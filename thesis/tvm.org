################################################################################
#+TITLE: ThesisVM BEng
#+AUTHOR: Kajetan Rzepecki
#+DATE: 2014
#
#+BEGIN_OPTIONS
#+BIND: org-export-latex-title-command ""
#+STARTUP: content
#+LaTeX_CLASS: aghdpl
#+LaTeX_CLASS_OPTIONS: [a4paper, 12pt]
#+LaTeX_HEADER: \usepackage[polish]{babel}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{multicol}
#+LATEX_HEADER: \usepackage[nottoc, notlof, notlot]{tocbibind}
#+OPTIONS: tags:nil, todo:nil, toc:nil, date:nil
#+END_OPTIONS
####################

# Helpers & Stuff
#+begin_src emacs-lisp :exports none
  (add-to-list 'org-export-latex-classes
               '("aghdpl"
                 "\\documentclass{aghdpl}"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")
                 ))
  (setq org-export-latex-classes (cdr org-export-latex-classes))
#+end_src

# AGH setup:
#+BEGIN_OPTIONS
#+LATEX_HEADER: \shortauthor{K. Rzepecki}
#+LATEX_HEADER: \degreeprogramme{Informatyka}

#+LATEX_HEADER: \thesistype{Praca dyplomowa inżynierska}

#+LATEX_HEADER: \titlePL{Implementacja maszyny wirtualnej dla funkcyjnych języków programowania wspierających przetwarzanie współbieżne.}
#+LATEX_HEADER: \titleEN{Implementation of a virtual machine for functional programming languages with support for concurrent computing.}

#+LATEX_HEADER: \shorttitlePL{Implementacja maszyny wirtualnej dla funkcyjnych języków programowania \dots}
#+LATEX_HEADER: \shorttitleEN{Implementation of a virtual machine for functional programming languages \dots}

#+LATEX_HEADER: \supervisor{dr inż. Piotr Matyasik}

#+LATEX_HEADER: \department{Katedra Informatyki Stosowanej}

#+LATEX_HEADER: \faculty{Wydział Elektrotechniki, Automatyki,\protect\\[-1mm] Informatyki i Inżynierii Biomedycznej}

##+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję opiekunowi pracy za wsparcie merytoryczne oraz dobre rady edytorskie pomocne w tworzeniu pracy.}
#+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję Lucynie za cierpliwość i wsparcie podczas tworzenia pracy.}
#+END_OPTIONS

# Title pages & table of contents:
#+begin_latex
\titlepages
\tableofcontents
#+end_latex

# List of Listings specific:
#+begin_latex
\newcommand{\listlistingname}{\bfseries\Large{Spis listingów}}
\newlistof[chapter]{mylisting}{mlol}{\listlistingname}
\newcommand{\mylisting}[1]{%
  \refstepcounter{mylisting}%
  #1%
  \addcontentsline{mlol}{figure}
    {\protect\numberline{\thechapter.\thelisting}#1}\par%
}
\renewcommand{\cftbeforemloltitleskip}{20mm}
\renewcommand{\cftaftermloltitleskip}{5mm}
#+end_latex

* COMMENT Wstęp
#+latex: \label{sec:intro}

Tematem pracy jest implementacja /maszyny wirtualnej/ dla funkcyjnych języków programowania wspierających /przetwarzanie współbieżne/.

Maszyna wirtualna jest warstwą abstrakcji leżącą pomiędzy programem a rzeczywistym sprzętem, która pozwala uniezależnić ów program od rozbieżności w działaniu różnych architektur komputerów. Wystarczy zaimplementować maszynę wirtualną dla danej architektury rzeczywistego sprzętu by umożliwić uruchamianie na niej wszystkich kompatybilnych z programów. Rysunek [[ref:fig:vm-arch]] prezentuje uproszczony schemat takiego rozwiązania - programy docelowe zostają skompilowane do /kodu bajtowego/ akceptowanego przez maszynę wirtualną a dopiero ów bajtkod jest przez nią uruchamiany.

#+begin_center
#+label: fig:vm-arch
#+caption: Schemat interakcji z Maszyną Wirtualną.
#+attr_latex: scale=0.7
[[file:./img/fullarch.pdf]]
#+end_center

Przetwarzanie współbieżne opiera się o współistnienie wielu procesów, które konkurują o dostęp do współdzielonych zasobów. W kontekście pracy, przetwarzanie współbieżne jest rozumiane jako asynchroniczne przekazywanie wiadomości pomiędzy działającymi, autonomicznymi procesami, czyli jako Model Aktorowy [[cite:Hewitt1973,Clinger1981]].

Celem pracy jest stworzenie interpretera kodu bajtowego zdolnego uruchamiać kod skompilowanych programów, kolektora obiektów nieosiągalnych umożliwiającego automatyczne zarządzanie pamięcią oraz architektury symetrycznego multiprocesora (SMP) zapewniającego rzeczywistą współbieżność uruchamianych programów w oparciu o Model Aktorowy.
Językiem implementacji projektu jest język =D= (w wersji 2.0 opisanej w [[cite:Alexandrescu2010]]), stosunkowo nowoczesny, kompilowany do kodu maszynowego następca języka =C++=.

** Motywacja pracy
#+latex: \label{sec:thesis-motivation}

Motywacją powstania pracy są problemy napotkane podczas użytkowania języka =Erlang= [[cite:Armstrong1996]], dotyczące wydajności przesyłania wiadomości średniego rozmiaru w obecnej, standardowej jego implementacji. Problemy owe zilustrowano na listingu [[ref:code:erlang-problem]].

Zaprezentowany fragment kodu odczytuje plik w formacie JSON, który następnie jest dekodowany do wewnętrznej reprezentacji posiadającej skomplikowaną strukturę, by ostatecznie został on wysłany do dużej liczby współbieżnie działających procesów celem dalszego przetwarzania (linia [[ref:line:bad]]). Rozwiązanie takie powoduje znaczący spadek wydajności.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Fragment kodu prezentujący problem występujący w języku \texttt{Erlang}.}}
#+latex: \label{code:erlang-problem}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src erlang
  start() ->
      Data = file:read("file.json"),    %% <<"Dane ...">>
      transmogrify(Data).
  
  transmogrify(Data) ->
      Pids = framework:spawn_bajilion_procs(fun do_stuff/1),
      JSON = json:decode(Data),         %% {[Dane ...]}
      framework:map_reduce(Pids, JSON). %% !#&^@ $\label{line:bad}$
  
  do_stuff(JSON) ->
      %% Operacje na danych.
      result.
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Język =Erlang= wykorzystuje skomplikowaną architekturę pamięci, która w różny sposób traktuje obiekty różnego typu. Większość obiektów, w szczególności skomplikowana strukturalnie reprezentacja danych w formacie JSON, przechowywana jest w prywatnych stertach każdego procesu i musi być kopiowana podczas przesyłania jej w wiadomościach pomiędzy nimi. Reguła ta nie dotyczy danych binarnych, w szczególności danych odczytanych z pliku, ponieważ te korzystają z innych algorytmów nie wymagających kopiowania kosztem większego zużycia pamięci.

W związku z tym, aby zaradzić problemowi opisanemu powyżej, wystarczy przenieść operację dekodowania danych odczytanych z pliku bezpośrednio do procesów na nich operujących (listing [[ref:code:erlang-solution]]).
W nowej wersji procesy przesyłają jedynie dane binarne, które nie wymagają kopiowania pamięci, a narzut wydajności spowodowany wielokrotnym ich dekodowaniem jest niższy niż ten spowodowany nadmiernym kopiowianiem. W efekcie, kod działa wydajniej, kosztem logiki przepływu danych i organizacji modułów.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Suboptymalne rozwiązanie problemu w języku \texttt{Erlang}.}}
#+latex: \label{code:erlang-solution}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true"))
#+begin_src erlang
  transmogrify(Data) ->
      Pids = framework:spawn_bajilion_procs(fun do_stuff/1),
      framework:map_reduce(Pids, Data).
  
  do_stuff(Data) ->             %% <<"Dane ...">>
      JSON = json:decode(Data), %% {[Dane ...]} * bazylion
      %% Operacje na danych.
      result.
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Celem pracy jest uniknięcie problemu nadmiernego kopiowania pamięci przez wybranie odpowiedniego modelu pamięci i implementację algorytmów kolekcji obiektow nieosiągalnych, które umożliwiają przesyłanie wiadomości pomiędzy procesami bez konieczności kopiowania ich zawartości.

** Zawartość pracy
W skład pracy wchodzi implementacja interpretera kodu bajtowego, kolektora obiektów nieosiągalnych oraz symetrycznego multiprocesora (SMP).

Sekcja [[ref:sec:intro]] opisuje cele, motywację, zakres oraz zawartość pracy.

Sekcja [[ref:sec:tvm-arch]] przybliża architekturę maszyny wirtualnej ThesisVM zaimplementowanej w ramach pracy, zaczynając od reprezentacji pośredniej programów (TVMIR) i jej kompilacji do kodu bajtowego, przez interpretację kodu bajtowego i zarządzanie pamięcią do projektu przetwarzania współbieżnego.

Sekcja [[ref:sec:tvm-vm]] szczegółowo opisuje implementację interpretera kodu bajtowego maszyny wirtualnej ThesisVM. Zaprezentowane zostają reprezentacje różnych obiektów, na których operuje maszyna, implementacja wpudowanych operatorów i funkcji prymitywnych oraz reprezentacja i generowanie kodu bajtowego akceptowanego przez interpreter.

Sekcja [[ref:sec:tvm-gc]] szczegółowo prezentuje implementację wybranego modelu pamięci, alokatora nowych obiektów oraz kolektora obiektów nieosiągalnych.

Sekcja [[ref:sec:tvm-smp]] szczegółowo opisuje implementację asynchronicznego przekazywania wiadomości i symetrycznego multiprocesora w maszynie ThesisVM. Zaprezentowana zostaje implementacja Modelu Aktorowego i harmonogramowania procesów.

Sekcja [[ref:sec:conclusion]] zawiera podsumowanie pracy oraz zarys możliwych kierunków dalszego rozwoju projektu.

Dodatki [[ref:sec:tvm-samples]], [[ref:sec:tvm-primops]] i [[ref:sec:misc]] zawierają odpowiednio wskazówki użytkowania ThesisVM i przykładowe programy gotowe do uruchomienia na maszynie wirtualnej, spis wbudowanych operatorów i funkcji prymitywnych oraz spisy rysunków, tablic i fragmentów kodu znajdujących się w tekście pracy.

* COMMENT Architektura ThesisVM
#+latex: \label{sec:tvm-arch}

Ninejsza sekcja opisuje architekturę maszyny wirtualnej ThesisVM powstałej na potrzeby pracy oraz języka przez nią akceptowanego.

Rysunek [[ref:fig:tvm-arch]] zawiera schematyczną reprezentację maszyny wirtualnej ThesisVM uwzględniającą architekturę procesora sprzętu, na którym działa system operacyjny oraz sama maszyna wirtualna. Na schemacie widać poszczególne podsystemy ThesisVM, takie jak autonomiczne procesy (zwane dalej /mikroprocesami/, =µProcN=), czy symetryczne multiprocesory (zwane dalej =SMPn=).

Mikroprocesy są przypisane do symetrycznych multiprocesorów w stosunku wiele-do-jednego, to znaczy każdy mikroproces jest przypisany do dokładnie jednego symetrycznego multiprocesora, który natomiast może zarządzać zbiorem wielu mikroprocesów.

#+begin_center
#+label: fig:tvm-arch
#+caption: Architektura maszyny wirtualnej ThesisVM.
#+attr_latex: scale=0.8
[[file:./img/arch.pdf]]
#+end_center

Każdy symetryczny multiprocesor działa w osobnym wątku procesora sprzętowego, zapewniając rzeczywistą współbieżność. Wszystkie =SMPn= są takie same i wykonują takie same zadania, czyli harmonogramowanie i wywłaszczanie mikroprocesów, a różni je jedynie stan, w którym się znajdują oraz zbiór procesów, którymi zarządzają.
Na schemacie widnieje mapowanie jeden-do-jednego pomiędzy rdzeniami procesora (=CPUn=) a poszczególnymi =SMPn=, nie jest to jednak wymóg konieczny i zależy od konfiguracji maszyny wirtualnej. Konfigurowalna ilość równocześnie działających SMP pomaga osiągnąć lepszą skalowalność maszyny wirtualnej i może być zmieniana dynamicznie wedle potrzeb.

Pozostając w zgodzie ze schematem przedstawionym na rysunku [[ref:fig:vm-arch]], interakcja z maszyną ThesisVM przebiega w analogiczny sposób. Kod programów w reprezentacji pośredniej (TVMIR) jest kompilowany do kodu bajtowego akceptowanego przez maszynę wirtualną, która następnie go ładuje i wykonuje umożliwiając zrównoleglenie obliczeń poprzez tworzenie nowych procesów i przesyłanie pomiędzy nimi wiadomości.

** Reprezentacja pośrednia programów
ThesisVM wykorzystuje prostą reprezentację pośrednią programów w postaci TVMIR - języka lisp'owego z rodziny =Scheme= [[cite:Abelson1996]], który jest dostatecznie ekspresywny, by można w nim było zapisać nietrywialne algorytmy, a jednocześnie na tyle prosty, by ułatwić jego późniejszą kompilację do kodu bajtowego akceptowanego przez maszynę wirtualną.

Języki pośrednie reprezentacji programów są często stosowane w implementacjach wielu maszyn wirtualnych, takich jak ParrotVM, czy CoreVM [[cite:PeytonJones1992]], a także w implementacjach kompilatorów kodu maszynowego wielu języków programowania (na przykład GCC, LLVM). Reprezentacje pośrednie mają wiele zalet, począwszy od ułatwienia wsparcia dla szerszej gamy języków wysokiego poziomu, na możliwości tworzenia wygodnych założeń dodatkowych kończąc.

Na listingu [[ref:code:tvmir]] spisana w formacie BNF została gramatyka języka reprezentacji pośredniej wykorzystanego w maszynie wirtualnej ThesisVM. Gramatyka ta jest nieskomplikowana i w dużej mierze przypomina gramatiki różnych dialektów języka =Lisp=.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Gramatyka języka TVMIR.}}
#+latex: \label{code:tvmir}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
# TODO Add primop, apply, send, receive and spawn.
#+begin_src xml
  <program>        ::= <definitions>
  <definitions>    ::= <definition> <definitions> | ''
  <definition>     ::= '(' 'define' '(' <symbol> <arguments> ')'
                                    <expression> ')'
  <arguments>      ::= <symbol> <arguments> | ''
  <expression>     ::= <value> | <application> | <primop>
                     | <conditional> | <quote> | <spawn>
  <value>          ::= <list> | <symbol> | <number>
  <application>    ::= '(' <expression> <expressions> ')'
  <expressions>    ::= <exrpession> <exrpessions> | ''
  <conditional>    ::= '(' 'if' <expression>
                                <expression>
                                <expression> ')'
  <quote>          ::= ''' <expression> | '(' 'quote' <epression> ')'
  <spawn>          ::= '(' 'spawn' <symbol> <expression> ')'
  <primop>         ::= '(' 'primop' <symbol> <expressions> ')'
  <list>           ::= '(' <expressions> ')'
  <symbol>         ::= <literal-string> | <atom>
  <literal-string> ::= '"' "Dowolny literał znakowy." '"'
  <atom>           ::= "Dowolny literał znakowy bez znaków białych."
  <number>         ::= "Dowolny literał liczbowy."
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Języki z rodziny =Lisp= są bardzo wygodnym medium dla pośredniej reprezentacji programów ponieważ przedstawiają one drzewo syntaktyczne analizowanego kodu programu i nie wymagają skomplikowanego algorytmu parsowania. Dodatkowo, homoikoniczność tych języków może pomóc w tworzeniu narzędzi służących do przetwarzania kodu rozpatrywanego języka (w szczególności kompilatorów) bezpośrednio w rozpatrywanym języku. Temat ten został dogłębnie zbadany w [[cite:Abelson1996]]. Dodatek [[ref:sec:tvm-samples]] zawiera przykłady kodu w języku pośredniej reprezentacji programów TVMIR.

Język reprezentacji pośredniej przedstawiony w pracy wymaga stworzenia kilku założeń dodatkowych dotyczących transformacji kodu. Najważniejszym z nich jest konieczność przeprowadzenia operacji lambda-unoszenia (ang. /lambda lifting/), opisanej bardzo dokładnie w [[cite:PeytonJones1992]], której efekt zaprezentowano na listingu [[ref:code:lambda-lifting]].

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Fragmenty kodu prezentujące operację lambda-unoszenia.}}
#+latex: \label{code:lambda-lifting}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))

#+latex: \begin{multicols}{2}
#+begin_src scheme
  ;; Przed lambda-unoszeniem:
  (define (make-adder n)
    (lambda (x)
      (+ x n)))
#+end_src

#+latex: \columnbreak
#+begin_src scheme
  ;; Po lambda-unoszeniu:
  (define (__make-adder_lambda0 n x)
    (+ x n))
  
  (define (make-adder n)
    (__make-adder_lambda n))
#+end_src
#+latex: \end{multicols}

#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Lambda-unoszenie polega na transformacji ciał funkcji w taki sposób, by tworzone w nich funkcje anonimowe zostały przeniesione na poziom główny zasięgu nazw (ang. /top-level scope/) dzięki czemu do ich implementacji wystarczy jedynie częściowa aplikacja funkcji. Na drugiej części listingu [[ref:code:lambda-lifting]] funkcja =make-adder= zwracająca anonimową funkcję została transformowana na dwie funkcje, z których =make-adder= pozostaje funkcją unarną, która korzysta z częściowej aplikacji funkcji binarnej =__make-adder_lambda0= wykonującej operację dodawania.

Pełna i poprawna implementacja operacji lambda-unoszenia jest skomplikowana, toteż nie została zawarta w dołączonym do projektu kompilatorze kodu bajtowego i musi zostać wykonana ręcznie.

Język pośredniej reprezentacji programów zastosowany w maszynie wirtualnej ThesisVM jest bardzo podobny do języka =Core Lang= wykorzystywanego w [[cite:PeytonJones1992]], jednak nie wspiera on niektórych jego konstrukcji, takich jak =let(rec)=, czy definicje dowolnych obiektów złożonych. Z drugiej strony wspiera on konstrukcje związane z Modelem Aktorowym (=receive=, =send= oraz =spawn=) oraz jest w stanie emulować brakujące konstrukcje odpowiednio przez wykorzystanie transformacji kodu połączonej z lambda-unoszeniem (listing [[ref:code:poor-mans-let]]) oraz "tagowania" list (przechowywania informacji o typie obiektu w pierwszym elemencie listy enkodującej ten obiekt).

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Ograniczona implementacja konstrukcji \texttt{let}.}}
#+latex: \label{code:poor-mans-let}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))

#+latex: \begin{multicols}{2}
#+begin_src scheme
  ;; Przed transformacją:
  (define (function x)
    (let ((value (* 2 x)))
      (* value value)))

  ;; Po transformacji:
  (define (function x)
    ((lambda (value)
       (* value value))
     (* 2 x)))
#+end_src

#+latex: \columnbreak
#+begin_src scheme
  ;; Po lambda-unoszeniu:
  (define (__function_lambda0 value)
    (* value value))

  (define (function x)
    (__function_lambda0 (* 2 x)))
#+end_src
#+latex: \end{multicols}

#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Kolejnym podobnym językiem reprezentacji pośredniej jest =Core Erlang= [[cite:Carlsson2001]] wykorzystywany w standardowej implementacji języka =Erlang=. TVMIR jest bardzo okrojoną wersją języka =Core Erlang=, pozbawioną elementów dopasowywania wzorców, która jednak wspiera pozostałe ważne jego elementy, takie jak konstrukcje odpowiedzialne za tworzenie procesów oraz przesyłanie i odbieranie wiadomości.
Istnieje możliwość rozszerzenia funkcjonalności TVMIR celem wsparcia pełnej specyfikacji =Core Erlang= [[cite:Carlsson2004]], jednak jest to poza zakresem pracy. Więcej informacji o przyszłych kierunkach rozwoju projektu zostało zawarte w sekcji [[ref:sec:future-development]].

** Kompilacja kodu bajtowego

Język pośredniej reprezentacji programów jest wygodnym medium do zapisu algorytmów, jednak wymaga on uprzedniego skompilowania do kodu bajtowego, który jest akceptowany przez maszynę wirtualną ThesisVM.

Ponieważ kompilacja kodu nie jest /stricte/ tematem pracy, mniej ważne szczegóły implementacji zostały pominięte, a niniejsza sekcja zarysowuje poszczególne fazy kompilacji kodu bajtowego ThesisVM.

Rysunek [[ref:fig:tvm-compiler-pipeline]] zawiera schemat działania kompilatora kodu bajtowego ThesisVM wraz z przykładami pośrednich reprezentacji kompilowanego kodu w poszczególnych fazach kompilacji.

#+begin_center
#+label: fig:tvm-compiler-pipeline
#+caption: Schemat potokowega działania kompilatora kodu bajtowego ThesisVM wraz ze przykładami reprezentacji danych poszczególnych faz kompilacji.
#+attr_latex: scale=0.5
[[file:./img/pipeline.pdf]]
#+end_center

Kompilator został zaimplementowany w sposób /potokowy/, to znaczy poszczególne fazy są logicznie odseparowane od siebie i wykonywane jedna po drugiej. Dzięki zastosowaniu leniwych konstrukcji języka =D= [[cite:Alexandrescu2010]] wszystkie te fazy odbywają się /jednocześnie/ i /na rządanie/ a w przypadku wykrycia błędu w danej fazie poprzednie fazy natychmiastowo się kończą, bez konieczności przetworzenia całego zestawu danych, które otrzymały na wejściu.

Pierwszą fazą jest faza analizy leksykalnej, której zadaniem jest przetworzenie /strumienia znaków/ kodu źródłowego programu w pośredniej reprezentacji TVMIR do /strumienia tokenów/, czyli elementarnych ciągów znaków będących leksemami języka. Faza ta przeprowadza także walidację składni na poziomie tokenów oraz filtrację niepotrzebnych tokenów (takich jak znaki białe, które nie mają znaczenia w TVMIR).

Drugą fazą jest faza analizy syntaktycznej, której zadaniem jest przetworzenie powstającego leniwie /strumienia tokenów/ na /wstępne drzewo parsowania/ składające się z prymitywnych konstrukcji języka TVMIR, takich jak listy, symbole i liczby. Faza ta waliduje składnię na poziomie zaawansowanych konstrukcji języka, które dzięki jego homoikoniczności zbudowane są z prymitywniejszych jego konstrukcji.

Trzecią fazą jest faza analizy semantycznej, której zadaniem jest przetworzenie /wstępnego drzewa parsowania/ na bardziej abstrakcyjne /drzewo składniowe/ (ang. /Abstract Syntax Tree/, /AST/) składające się semantycznie znaczących węzłów, takich jak aplikacja funkcji, wywołania operatorów wbudowanych, czy odwołania do zmiennych. Faza ta waliduje kod na poziomie semantycznym, sprawdzając poprawność wykorzystania różnych konstrukcji języka TVMIR.

Czwartą fazą jest faza optymalizacji, której zadaniem jest transformacja /drzewa składniowego/ powstałego w poprzedniej fazie do jego ekwiwalentu działającego szybciej po skompilowaniu. Faza ta obecnie nie wykonuje żadnych interesujących transformacji, jednak istnieje możliwość rozszerzenia jej funkcjonalności w przyszłości (opisane krótko w sekcji [[ref:sec:future-development]]).

Ostatnią, piątą fazą kompilacji jest faza generacji kodu bajtowego akceptowanego przez ThesisVM. Zadaniem tej fazy jest przetworzenie /drzewa składniowego/ do /strumienia kodu bajtowego/ za pomocą reguł kompilacji zgodnych z wybranym modelem maszyny wirtualnej.

** Interpretacja kodu bajtowego
Istnieje wiele różnych modeli maszyn wirtualnych cechujących się różnymi architekturami interpreterów kodu bajtowego, czy nawet stopniem abstrakcyjności (tak zwane maszyny abstrakcyjne).

Pod względem architektury interpretera kodu bajtowego można wyróżnić trzy główne architektury maszyn wirtualnych:

- architekturę *stosową*, korzystającą ekskluzywnie z jednego lub wielu stosów podczas przetwarzania danych, która charakteryzuje się krótkimi, pod względem zajmowanej pamięci, instrukcjami;

- architekturę *rejestrową*, korzystającą ekskluzywnie z wielu rejestrów podczas przetwarzania danych, która charakteryzuje się instrukcjami przyjmującymi wiele argumentów określających adresy rejestrów maszyny;

- architektury *hybrydowe*, łączące dwa powyższe rozwiązania w różnym stopniu.

Pod względem abstrakcyjności maszyny wirtualne można podzielić na dwie główne grupy:

- *niskopoziomowe*, do których należą maszyny implementujące wyżej wymienione architektury; główną cechą maszyn niskopoziomowych jest obecność stosunkowo nieskomplikowanego kodu bajtowego, który jest przez maszynę interpretowany podczas jej działania;

- *wysokopoziomowe*, które wymagają niestandardowego traktowania kodu programów; na przykład maszyna redukcji grafowych G-machine wykorzystująca grafową naturę kodu języków funkcyjnych do zrównoleglenia jego ewaluacji, opisana szczegółowo w [[cite:PeytonJones1992]].

Od wyboru architektury interpretera kodu bajtowego bardzo często zależą dostępne funkcjonalności docelowego języka programowania. W celu wybrania odpowiedniej architektury należy przeprowadzić szczegółową analizę porządanych funkcjonalności implementowanego języka i możliwości ich zrealizowania w poszczególnych modelach maszyny wirtualnej. Szczegółowa analiza wpływu języka na możliwość jego zaimplementowania w danej architekturze została zawarta w [[cite:Steele1978]] wraz z praktycznymi wskazówkami dotyczącymi implementacji maszyn wirtualnych, co okazało się niezastąpionym źródłem wiedzy pomocnym przy implementacji ThesisVM.

Interpreter kodu bajtowego zaimplementowany w ramach pracy wykorzystuje niskopoziomową architekturę stosową wykorzystującą wiele stosów oraz niewielki zbiór rejestrów i jest zmodyfikowaną wersją interpretera opisanego w $\cite[\text{rozdział 4}]{PeytonJones1992}$. Szczegółowy opis implementacji został zawarty w dedykowanej mu sekcji [[ref:sec:tvm-vm]] pracy.

** Zarządzanie pamięcią
#+latex: \label{sec:tvm-heap-archs}

Ważnym aspektem architektury maszyny wirtualnej jest sposób w jaki wykorzystuje ona pamięć operacyjną i rozdziela ją pomiędzy procesy w niej działające, czyli architektura wykorzystania sterty (ang. /heap architecture/).

Rysunek [[ref:fig:mem-archs]] przedstawia trzy główne architektury wykorzystania sterty w środowisku wielo-procesowym, gdzie wiele autonomicznych procesów konkuruje o zasób jakim jest pamięć:

- architektura *sterty prywatnej*, charakteryzująca się zupełną separacją pamięci poszczególnych procesów, co prowadzi do konieczności kopiowania obiektów składających się na wiadomości przesyłane pomiędzy nimi;

- architektura *sterty współdzielonej*, charakteryzująca się współdzieleniem jednego obszaru pamięci pomiędzy wszystkie procesy, dzięki czemu wiadomości (a także ich części) mogą być współdzielone przez procesy bez konieczności ich kopiowania;

- architektura *hybrydowa*, mająca za zadanie połączenie zalet obu powyższych rozwiązań przez separację danych lokalnych procesów i współdzielenie danych wiadomości przesyłanych pomiędzy procesami; rozwiązanie to wymaga skomplikowanej, statycznej analizy kodu programów, która nie zawsze może być przeprowadzona.

#+begin_center
#+label: fig:mem-archs
#+caption: Różne modele wykorzystania pamięci maszyn wirtualnych.
#+attr_latex: scale=1.0
[[file:./img/mem.pdf]]
#+end_center

Szczegółowa analiza wydajności architektur przedstawionych na rysunku [[ref:fig:mem-archs]] w kontekście języka =Erlang=, do semantyki którego ThesisVM jest bardzo zbliżona, została zawarta w [[cite:Wilhelmsson2005]]. Na podstawie tej analizy zdecydowano się zastosować architekturę sterty współdzielonej, która minimalizuje problem kopiowania pamięci (/ergo/, spełnia nieformalny cel pracy sformułowany w sekcji [[ref:sec:thesis-motivation]]) oraz nie wymaga skomplikowanej statycznej analizy kodu programów. Implementacja pozostawia jednak możliwość późniejszej modyfikacji architektury wykorzystania sterty.

Z problemem architektury wykorzystania sterty ściśle związany jest problem wyboru algorytmu alokacji pamięci. W [[cite:Wilson1995]] zawarto obszerne zestawienie algorytmów alokacji pamięci, na podstawie, którego zdecydowano się wykorzystać alokatory kaskadowe, /cache/'ujące pamięć zwolnionych obiektów w celu optymalizacji alokacji. Implementacja zastosowanego alokatora została zawarta w sekcji [[ref:sec:tvm-gc]].

Ostatnim aspektem zarządzania pamięci maszyny wirtualnej jest kolekcja pamięci obiektow nieosiągalnych. Kolektory obiektów nieosiągalnych można podzielić na dwa typy, ze względu na dane, które analizują:

- kolektory *śledzące* (ang. /tracing-GC/), które okresowo trawersują zbiór obiektów bazowych (ang. /root-set/) celem oznaczenia wszystkich obiektów /osiągalnych/ w danej chwili w systemie;

- kolektory *zliczające* (ang. /reference-counting-GC/), które na bieżąco zliczają ilość aktywnych referencji do każdego obiektu i natychmiastowo usuwają obiekty, których licznik referencji osiąga zero, co oznacza, że dany obiekt jest /nieosiągalny/.

Kolektory różnych typów mają bardzo różne charakterystyki wydajnościowe w zależności od architektury wykorzystania sterty zastosowanej w maszynie wirtualnej. Kolektory śledzące przeważnie generują długie pauzy w architekturach współdzielonych, natomiast kolektory zliczające prezentują stały narzut obliczeniowy związany z ciągłą modifykacją liczników referencji. Oczywiście istnieją dobrze poznane metody optymalizacji obu typu algorytmów [[cite:Shahriyar2012,Bacon2004]], które zacierają wszelkie różnice w ich charakterystykach wydajnościowych.

W implementacji ThesisVM zdecydowano się wykorzystać mechanizm automatycznej kolekcji "śmieci", oparty o /leniwe zliczanie referencji/, na podstawie wnikliwej analizy zawartej w [[cite:Bacon2004]] oraz w związku z wykorzystaniem podobnych algorytmów kolekcji danych binarnych w standardowej implementacji języka =Erlang=. Rozwiązanie to zostało szczegółowo opisane w sekcji [[ref:sec:tvm-gc]], a implementacja umożliwia późniejsze jej rozszerzenie o dodatkowe optymalizacje. Do alternatywnych rozwiązań należą te zaprezentowane w [[cite:Armstrong1995]] oraz [[cite:Huelsbergen1998]].

** Przetwarzanie współbieżne
Systemy współbieżne często realizują model symetrycznego multiprocessingu (/SMP/), którego cechą szczególną jest istnienie wielu identycznych jednostek operacyjnych wykonujących jednakowe operacje na różnych zbiorach danych (=SMPn= na rysunku [[ref:fig:amp-vs-smp]]).

#+begin_center
#+label: fig:amp-vs-smp
#+caption: Różne modele przetwarzania współbieżnego.
#+attr_latex: scale=0.5
[[file:./img/ampvssmp.pdf]]
#+end_center

Alternatywnym rozwiązaniem jest model asymetrycznego multiprocessingu (/AMP/) (=AMPn= na rysunku [[ref:fig:amp-vs-smp]]), gdzie dla różnych typów zadań istnieją dedykowane, wyspecjalizowane jednostki operacyjne, takie jak wątki, lub procesy systemu operacyjnego.

Rozwiązania asymetryczne są interesujące ze względu na zupełnie nowe klasy algorytmów, których implementację umożliwiają (na przykład algorytm zarządzania pamięcią VCGC [[cite:Huelsbergen1998]] wykorzystujący trzy asymetryczne wątki), jednak charakteryzują się skomplikowaniem interakcji poszczególnych jednostek operacyjnych a niejednokrotnie także słabą skalowalnością całego rozwiązania.

# TODO Rewrite the preceeding sentence.

Model przetwarzania współbieżnego został już przybliżony przy okazji ogólnego opisu architektury ThesisVM na początku rozdziału. Wybrany został model SMP, który w kontekście maszyny wirtualnej ThesisVM polega na zrównolegleniu wielu interpreterów kodu bajtowego operujących na różnych kontekstach procesów (zbiorach rejestrów i danych znajdujących się na ich stosach) w celu osiągnięcia realnej współbieżności interpretowanego kodu.

Dodatkową zaletą modelu SMP jest jego kompatybilność z Modelem Aktorowym [[cite:Hewitt1973]], którego głównym założeniem jest istnienie autonomicznych aktorów, którzy reagując na zmiany otoczenia dążą do swoich celów porozumiewając się z innymi aktorami za pośrednictwem wysyłania wiadomości [[cite:Clinger1981]]. W modelu SMP zastosowanym w maszynie wirtualnej ThesisVM aktorami są poszczególne procesy, które porozumiewają się za pomocą asynchronicznych wiadomości przesyłanych poprzez nieblokujące kolejki FIFO (ang. /First In First Out/).

Szczegółowy opis implementacji symetrycznego multiprocesora i realizacja Modelu Aktorowego za jego pomocą zostały zawarte w sekcji [[ref:sec:tvm-smp]].

* COMMENT Interpreter kodu bajtowego
#+latex: \label{sec:tvm-vm}

Niniejszy rozdział opisuje implementację interpretera kodu bajtowego ThesisVM. Jak już wspomniano w poprzedniej sekcji, praca implementuje model /Three Instruction Machine/, opisany szczegółowo w [[cite:Fairbairn1987]]
 oraz [[cite:PeytonJones1992]], wprowadzając do niego szereg modyfikacji.

Three Instruction Machine (TIM) jest nieskomplikowanym modelem maszyny wirtualnej opartym o trzy rejestry, służące do manipulacji danych:

- *IP* - wskaźnik /kodu/ następnej instrukcji,

- *Stack* - stos /kontynuacji/ skłądających się z wskaźnika do kodu oczekującego na ewaluację oraz kontekstu, w którym należy ów kod ewaluować,

- *Env* - stos będący obecnym /kontekstem/ ewaluacji kodu, który jest analogiczny do leksykalnego zasięgu zmięnnych w kodzie źródłowym programu;

#+latex: \noindent
oraz trzy bazowe instrukcje przyjmujące od zera do jednego argumentu, które w zupełności wystarczą do implementacji leniwych, funkcyjnych języków programowania:

- *PUSH arg* - tworzy kontynuację argumentu, która umożliwia jej późniejszą ewaluację w odpowiednim kontekście, odkładając ją na stos =Stack=,

- *TAKE* - pobiera kontynuację ze stosu Stack i przenosi ją na stos =Env= rozszerzając obecny kontekst ewaluacji kodu i przygotowując środowisko ewaluacji danej funkcji,

- *ENTER arg* - inicjuje ewaluację kontynuacji wskazywanej przez argument instrukcji odpowiednio modyfikując wartość rejestrów =IP= i =Env=.

#+latex: \noindent
Dodatkowo, instrukcje TIM posiadają różne typy adresowania argumentów, które wpływają na sposób interpretacji argumentu instrukcji:

- *VAL* - argument jest traktowany jako konkretna wartość,

- *CODE* - argument jest traktowany jako wskaźnik do konkretnej wartości,

- *ARG* - argument jest traktowany jako indeks stosu =Env=,

Ewaluacja kodu bajtowego TIM przebiega w standardowy sposób. Instrukcje pobierane są z adresu wskazywanego przez wskaźnik następnej instrukcji =IP=, po czym są dekodowane i wykonywane. Dekodowanie instrukcji polega na pobraniu kodu instrukcji oraz sposobu odresowania argumentu. Ostatnią fazą jest ustalenie konkretnej wartości argumentu na podstawie wcześniej ustalonego adresowania.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Przykład kodu bajtowego Three Instruction Machine.}}
#+latex: \label{code:tim-example}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src python
        PUSH ARG 0  # func
        ENTER ARG 0 # func
  func: TAKE
        PUSH ARG 0  # arg
        ENTER ARG 1 # func
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Na listingu [[ref:code:tim-example]] zawarto przykład kodu bajtowego definicji funkcji =func=, która przyjmuje jeden argument =arg= oraz wywołuje samą siebie z tym argumentem. Przed definicją funkcji (dwie instrukcji przed etykietą =func:=) zawarto także przykładowe wywołanie tej funkcji.

Warto zauważyć, że argumenty przekazywane do funkcji w modelu TIM są ewaluowane /leniwie/ - w przykładzie widniejącym na listingu [[ref:code:tim-example]] widać, że argument =arg= nigdy nie jest ewaluowany, nawet pomimo faktu, że funkcja =func= przekazuje go do następnego wywołania. Argumenty są ewaluowane dopiero w momencie, gdy maszyna potrzebuje ich konkretnej wartości.

Drugim ważnym spostrzeżeniem jest wsparcie /optymalizacji rekursji ogonowej/ modelu TIM - jeśli ostatnią instrukcją kodu ciała funkcji jest wywołanie innej funkcji, to wynikowy kod bajtowy zakończony będzie instrukcją ENTER, która nie wymaga zapisywania adresu powrotnego i tym samym gwarantuje stałą wielkość stosu programu.

Model Three Instruction Machine został wybrany jako podstawa implementacji ThesisVM ze względu na swoją prostotę i niewątpliwe zalety jakie posiada w kontekście implementacji funkcyjnych języków programowania. Istnieje wiele alternatywnych modeli działania maszyn wirtualnych, jak na przykład model /SECD/ [[cite:VanHorn2010]] oraz jego rekursywny ogonowo wariant /TR-SECD/ [[cite:Ramsdell1999]], czy bardziej adekwatne dla języków z rodziny Lisp modele opisane w [[cite:Abelson1996]] oraz [[cite:Steele1978]].

** Modyfikacje i implementacja modelu TIM
#+latex: \label{sec:tim-impl}

Zaprezentowany powyżej model jest bardzo prosty i pomimo swojej niewątpliwej ekspresywności, maszyna wirtualna go implementująca nie byłaby w stanie uruchamiać programów o praktycznym zastosowaniu. W związku z tym, model został rozszerzony o dodatkowy rejestr wskazujący na stos danych "prostych", nie będących kontynuacjami, a takżge szereg instrukcji implementujących podstawowe instrukcje arytmetyczne, logiczne i związane z implementacją Modelu Aktorowego.

#+begin_center
#+label: fig:tvm-regs
#+caption: Schemat stanu maszyny wirtualnej.
#+attr_latex: scale=1.5
[[file:./img/uProc.pdf]]
#+end_center

Na rysunku [[ref:fig:tvm-regs]] widnieje schemat rejestrów wykorzystywanych przez interpreter kodu bajtowego. Wymienione rejestry wraz z pozostałymi, opisanymi w następnych sekcjach pracy, składają się na kontekst mikroprocesów ThesisVM.

Rejestr *Header* zawiera informacje o typie procesu oraz metadane kolektora obiektów nieosiągalnych. Konteksty mikroprocesów maszyny ThesisVM są dostępne z poziomu kodu źródłowego, ponieważ są obiektami pierwszej klasy (ang. /first-class object/). Więcej informacji na temat zastosowania tego rejestru zostało zawarte w sekcji [[ref:sec:compound-objects]] opisującej implementację obiektów złożonych ThesisVM.

Rejestr *IP* służy do przechowywania wskaźnika następnej instrukcji kodu bajtowego. Jest wykorzystywany w dokładnie taki sam sposób, jak analogiczny rejestr modelu TIM. Rejestry *Env* oraz *Stack* podobnie jak rejestr =IP= również wykorzystywane są zgodnie z opisem modelu TIM.

Ostatni rejestr, *VStack* wskazuje na stos przechowujący dane "proste", czyli obiekty, które nie wymagają ewaluacji przez interpreter i mogą być wykorzystywane przez operacje prymitywne. Funkcjonalność tego stosu nie mogła zostać połączona z funkcjonalnością stosu =Stack=, ponieważ część instrukcji polega na homogeniczności danych znajdujących się na stosie =Stack= - jeśli istnienie na tym stosie danych innych niż kontynuacje zostałoby dozwolone, to część instrukcji wymagałaby kosztownego przeszukiwania i modyfikacji stosu.

Implementacja ThesisVM modyfikuje semantykę trzech bazowych instrukcji TIM:

- *NEXT addr arg* - jest to bardziej adekwatnie nazwany analog instrukcji =PUSH= podstawowego modelu TIM, w zależności od typu adresowania argument instrukcja ta tworzy i umieszcza na stosie =Stack= samo-ewaluującą do wartości argumentu kontynuację (=addr= równe =VAL=), kontynuację składającą się z obecnego kontekstu i wartości wskazywanej przez argument (=addr= równe =CODE=) lub wartść kontynuacji znajdującej się na stosie =Env= (wartość =addr= równa =ARG=);

- *TAKE* - podobnie jak w przypadku modelu bazowego, pobiera jedną kontynuację ze stosu kontynuacji =Stack= i umieszcza ją w obecnym kontekście ewaluacji =Env=;

- *ENTER addr arg* - w zależności od typu adresacji argumentu odpowiednio modyfikuje wartości rejestrów =Env= oraz =IP= podstawiając wartość =IP= na wartość argumentu (=addr= równe =CODE=), lub ewaluując kontynuację znajdującą się na stosie =Env= (wartość =addr= równa =ARG=);

#+latex: \noindent
oraz wprowadza kilka nowych instrukcji służących do obsługi dodatkowego rejestru i operacji prymitywnych z nim związanych:

- *PUSH arg* - jest to prosta instrukcja, której jedynym zadaniem jest umieszczenie argumentu na stosie =VStack=;

- *PRIMOP arg* - wykonuje operację prymitywną o identyfikatorze równym wartości argumentu. Więcej informacji o implementacji operacji prymitywnych zawarto w sekcji [[ref:sec:tvm-primops-impl]];

- *COND arg* - jest to instrukcja warunkowa, która sprawdza wartość znajdującą się na wierzchu stosu =VStack= i w zależności od jej wartości wybiera jedną z dwóch gałęzi kodu wskazywanych przez argument i ustawia jej wartość jako nową wartość rejestru =IP=;

- *SPAWN arg* - jest to instrukcja związana z implementacją Modelu Aktorowego, tworzy ona nowy kontekst mikroprocesu ThesisVM i aranżuje ewaluację kontynuacji znajdującej się na stosie =Env= pod indeksem równym wartości argumentu instrukcji (=arg=) przekazując jej jako parametr wartość znajdującą się na szczycie stosu =VStack=. Tak zaaranżowany kontekst mikroprocesu jest następnie dodawany do kolejki uruchomieniowej jednego z symetrycznych multiprocesorów wybranego zgodnie z zasadami równoważenia obciążenia (opisanymi w sekcji [[ref:sec:tvm-scheduling]]);

- *HALT* - instrukcja ta usypia proces na czas nieokreślony efektywnie kończąc jego działanie. Tak zatrzymany proces następnie podlega kolekcji przez kolektor obiektów nieosiągalnych, ponieważ mogą istnieć referencje nań wskazujące, które są wykorzystywane przez inne procesy.

** Implementacja obiektów prostych
Dane programów w maszynie ThesisVM reprezentowane są za pomocą dwóch rodzajów obiektów - obiektów "prostych" oraz obiektów złożonych. Rysunek [[ref:fig:tvmvalue-impl]] zawiera schemat reprezentacji obiektów prostych, które należą do jednego z trzech wspieranych typów podstawowych: =POINTER=, =FLOATING= lub =INTEGER=.

#+begin_center
#+label: fig:tvmvalue-impl
#+caption: Schemat reprezentacji obiektów prostych ThesisVM.
#+attr_latex: scale=0.6
[[file:./img/tvmvalue.pdf]]
#+end_center

Implementacja przechowuje dane obiektów prostych w strukturze o wielkości jednego słowa procesora (*64* bity w obecnej implementacji maszyny wirtualej przystosowanej do architektury *x86_64*), która zapewnia dostęp do dwóch pól identyfikujących odpowiednio 61-bitową wartość przechowywaną w strukturze oraz 3-bitowy typ, do którego owa wartość należy.

Wartość przechowywane są wraz z informacją o ich typie, w celu umożliwienia implementacji języków dynamicznie typowanych oraz ułatwienia pracy kolektora obiektów nieosiągalnych - dzięki informacji o typie może on precyzyjnie określić, czy dany obiekt jest referencją, czy też nie.

Typy obiektow prostych przechowywane są w trzech najmniej znaczących bitach (ang. /least significant bits/, /LSB/) reprezentacji, umożliwiając implementację ośmiu różnych typów podstawowych, zgodnie ze szczegółowym opisem zawartym w [[cite:Gudeman1993]]. Reprezentacja taka posiada szereg zalet począwszy od kompaktowości, przez brak konieczności alokacji pamięci dla typów podstawowych, kończąc na wielu ciekawych optymalizacjach, które umożliwia.

Na przykład, jeśli alokator maszyny wirtualnej wymusi /wyrównywanie pamięci/ (ang. /alignment/) do wielkości słowa procesora, to trzy najmniej znaczące bity (na architekturze 64-bitowej) reprezentacji wskaźników zawsze będą zerowe. W związku z tym, zerem można reprezentować typ wskaźnikowy obiektow prostych ThesisVM (typ =POINTER=), co umożliwia wykorzystywanie ich reprezentacji bezpośrednio, bez konieczności przeprowadzenia operacji bitowego maskowania.

Podobne optymalizacje mogą zostać zastosowane w przypadku reprezentacji obiektów numerycznych. Na przykład, w celu dodania dwóch liczb całkowitych (o typie =INTEGER=) można posłużyć się ostatnią zależnością zaprezentowaną na listingu [[ref:code:integer-optimization]] zamiast wielokrotnie wykorzystywać kosztowne operacje =tag= i =untag=, które realizują przejścia pomiędzy reprezentacją wewnętrzną obiektów maszyny wirtualnej a reprezentacją języka jej implementacji.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Optymalizacja dodawania liczb całkowitych.}}
#+latex: \label{code:integer-optimization}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src d
result = tag(TVMValue.INTEGER, untag(a) + untag(b));
result = a.rawValue + b.rawValue - TVMValue.INTEGER;
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Wiele ciekawych optymalizacji związanych ze sposobem reprezentacji typów obiektów zostało zawarte w [[cite:Gudeman1993]].

** Implementacja obiektów złożonych
#+latex: \label{sec:compound-objects}
Ważnym elementem każdego języka programowania są złożone struktury danych takie jak listy lub drzewa. Rysunek [[ref:fig:tvmobject-impl]] prezentuje schemat reprezentacji obiektów złożonych ThesisVM, które służą do budowy takich struktur danych.

#+begin_center
#+label: fig:tvmobject-impl
#+caption: Schemat reprezentacji obiektów złożonych ThesisVM.
#+attr_latex: scale=0.6
[[file:./img/tvmobject.pdf]]
#+end_center

Obiekty te składają się z wielu słów procesora ułożonych kolejno w pamięci. Pierwszym słowem składającym się na obiekt złożony jest jego *nagłówek*, który zawiera między innymi ośmio-bitowy identyfikator typu obiektu oraz metadane kolektora obiektów nieosiągalnych.

Podobnie jak w przypadku obiektów prostych, informacja o typie jest wykorzystywana do implementacji języków dynamicznie typowanych oraz w celu ułatwienia pracy kolektora "śmieci". Identyfikator typu obiektu jest jednak znacznie większy pozwalając na reprezentację 256 różnych wartości, a co za tym idzie 256 różnych typów. Obecna implementacja nie wykorzystuje potencjału dłuższego identyfikatora typu w pełni, ale w przyszłości może zostać rozwinięta, na przykład w celu umożliwienia definiowania nowych typów danych.

Dodatkowym atutem stosowania nagłówka jest fakt, że wszystkie obiekty złożone ThesisVM mogą być traktowane w jednolity sposób za pośrednictwem wskaźników do owego nagłówka. Informacja o typie obiektu w nim zawarta może zostać wykorzystana do łatwego określenia faktycznej struktury obiektu znajdującego się w pamięci. Metoda ta została szeroko opisana w [[cite:Gudeman1993]] i jest standardowym rozwiązaniem wielu maszyn wirtualnych.

Po nagłówku występują właściwe dane w postaci =n= obiektów prostych, gdzie =n= jest dowolną liczbą naturalną. Ich zawartość =Wn= oraz typy =Tn= zależą w dużej mierze od typu całego obiektu złożonego, ale w ogólności podlegają wszystkim zasadom, którym podlegają obiekty proste.

Obecna implementacja definiuje 4 typy obiektów złożonych: =PAIR=, =CLOSURE=, =SYMBOL= oraz =UPROC=.

*Pary* składają się z nagłówka oraz dwóch obiektów prostych odpowiadających odpowiednio pierwszemu i drugiemu elementowi pary. Pary są wykorzysytwane do implementacji list, które z kolei są podstawowymi strukturami danych języka TVMIR, podobnie jak w innych językach z rodziny Lisp.

*Obiekty funkcyjne*, zwane czasami domknięciami leksykalnymi (ang. /closures/), służą do reprezentowania skompilowanych funkcji TVMIR oraz *kontynuacji* będących podstawą działania modelu TIM. W obu przypadkach obiekty funkcyjne składają się z dwóch obiektów prostych odpowiadających kolejno rejestrowi =IP= oraz stosowi =Env=.

Różnica pomiędzy skompilowanymi funkcjami oraz kontynuacjami sprowadza się do zestawu instrukcji zawartego w komponencie =IP= obiektu funkcyjnego - funkcje przyjmujące parametry wymagają pobrania ich wartości za pomocą instrukcji =TAKE=.

*Symbole* również składają się z nagłówka oraz dwóch obiektów prostych, które oznaczają odpowiednio wskaźnik na zewnętrzny fragment pamięci zawierający tekstową reprezentację symbolu i długość owej reprezentacji. Reprezentacja symboli została pomyślana w taki sposób, by umożliwiała bezpośrednie mapowania reprezentacji tekstowej na dostępny w języku D typ danych =string=, co znacząco ułatwia obsługę symboli w implementacji maszyny wirtualnej.

Ostatnim dostępnym typem danych ThesisVM jest *deskryptor mikroprocesu*. Deskryptory te są obiektami pierwszej klasy, co oznacza, że są w pełni dostępne dla użytkownika ThesisVM. Konteksty mikroprocesów składają się z nagłówka oraz ośmiu obiektów prostych, z których cztery pierwsze odpowiadają opisanym w poprzedniej sekcji rejestrom maszyny wirtualnej, a cztery następne zawierają dane wykorzystywane przez pozostałe moduły maszyny wirtualnej. Obiekty te zostały opisane w sekcjach [[ref:sec:tvm-gc]] oraz [[ref:sec:tvm-smp]].

** Implementacja i obsługa kodu bajtowego
Instrukcje kodu bajtowego ThesisVM dzielą reprezentację z obiektami złożonymi. Podobnie jak pary składają się z nagłówka obiektu oraz dwóch obiektów prostych, z których pierwszy określa identyfikator instrukcji oraz sposób adresowania argumentu, a drugi przechowuje wartość argumentu instrukcji. Dostępne instrukcje kodu bajtowego zostały już opisane w sekcji [[ref:sec:tim-impl]].

Reprezentacja kodu bajtowego wykorzystywana obecnie w maszynie wirtualnej niestety jest sub-optymalna. Alternatywnym rozwiązaniem mogło by być zastosowanie reprezentacji opartej o obiekty proste polegającej na przechowywaniu identyfikatorów instrukcji w najbardziej znaczącym bajcie obiektu.

Dekodowanie argumentu instrukcji wymagałoby wówczas jedynie przeskalowania pozostałych bajtów obiektu prostego celem odtworzenia rzeczywistej jego wartości, lub w przypadku niewielkich liczb całkowitych i typu wskaźnikowego, jedynie zastosowania masek bitowych.

Instrukcje pobierane są ze /strumienia kodu bajtowego/ wskazywanego przez rejestr =IP=. W obecnej implementacji strumień kodu bajtowego zrealizowany jest jako lista pojedynczo wiązana zbudowana z obiektów złożonych ThesisVM - par.

Reprezentacja ta została wybrana ze względu na charakter języka TVMIR (jest to język z rodziny Lisp) oraz przez wzgląd na podobieństwo to obsługi stosów =Stack=, =Env= oraz =VStack=, które również zostały zrealizowane w oparciu o listy pojedynczo wiązane. W przyszłości implementacja ta może zostać zastąpiona rozwiązaniem szybszym, niekoniecznie opartym o listy (więcej informacji na ten temat zawarto w sekcji [[ref:sec:future-development]]).

Po przechwyceniu pierwszego elementu listy wskazywanej przez rejestr =IP= następuje ustalenie identyfikatora instrukcji, sposobu adresowania argumentu oraz samej wartości argumentu instrukcji.
Następnie interpreter ewaluuje instrukcję zgodnie z regułami opisanymi w sekcji [[ref:sec:tim-impl]].

** Implementacja operacji prymitywnych
#+latex: \label{sec:tvm-primops-impl}

Operacje wbudowane, takie jak arytmetyka, czy funkcje związane z implementacją Modelu Aktorowego zostały zrealizowane w oparciu o rejestr =VStack= - argumenty operacji prymitywnych są pobierane ze stosu a wartości przez nie zwracane są nań odkładane. Listing [[ref:code:primops-algorithm]] zawiera ogólny algorytm implementacji operacji prymitywnych ThesisVM.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Ogólny algorytm implementacji operacji prymitywnych ThesisVM.}}
#+latex: \label{code:primops-algorithm}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src d
  arg0 = typecheck(t0, pop(uProc.vstack));
  // ...
  argN = typecheck(tN, pop(uProc.vstack));
  
  // Obliczenia charakterystyczne dla danej operacji.
  result = compute(arg0, ..., argN);
  
  push(uProc.vstack, result);
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Instrukcja wykonujące operacje primitywne, =PRIMOP id=, wykorzystuje metodę LUT (ang. /look-up table/) w celu skorelowania identyfikatora operacji prymitywnej i fragmentu kodu odpowiedzialnego za jej wykonanie - wykonanie tej instrukcji polega na przekazaniu przepływu sterowania do odpowiedniej funkcji znajdującej się w /tablicy operacji prymitywnych/.

Dostępne operacje prymitywne to w dużej mierze podstawowe operacje arytmetyczno-logiczne oraz funkcje typowe dla języków z rodziny Lisp, takie jak =cons=, =car=, czy =cdr= (więcej informacji można znaleźć w [[cite:Abelson1996]]). Lista wszystkich dostępnych operacji prymitywnych została zawarta w dodatku [[ref:sec:tvm-primops]].

Ponownie uwagę można zwrócić na podobieństwo traktowania operacji prymitywnych do języka =Core Erlang= [[cite:Carlsson2004]]. Podobieństwo to nie jest przypadkowe, a wybrany sposób reprezentacji i działania operacji prymitywnych został zaimplementowany w taki sposób, by w przyszłości umożliwić łatwe rozszerzenie implementacji maszyny wirtualnej ThesisVM oraz wsparcie pełni języka =Core Erlang=.

* COMMENT Model zarządzania pamięcią
#+latex: \label{sec:tvm-gc}

Niniejsza sekcja opisuje implementację modelu zarządzania pamięcią zastosowanego w maszynie wirtualnej ThesisVM, na który składa się architektura wykorzystania pamięci, algorytm alokacji obiektów oraz algorytm kolekcji obiektów nieosiągalnych. Wstępny opis wybranego modelu pamięci oraz motywacja tego wyboru zostały zawarte w sekcji [[ref:sec:tvm-heap-archs]].

** Architektura współdzielonej sterty
Na rysunku [[ref:fig:tvm-shared-mem]] zawarto schemat architektury sterty wykorzystanej w ThesisVM. Jest to architektura współdzielonej sterty, w której każdy z mikroprocesów alokuje obiekty na własny użytek. Obiekty te lub ich części mogą być następnie współdzielone pomiędzy mikroprocesami w wyniku przesyłania wiadomości.

#+begin_center
#+label: fig:tvm-shared-mem
#+caption: Model współdzielonej pamięci ThesisVM.
#+attr_latex: scale=1.5
[[file:./img/sharedmem.pdf]]
#+end_center

Kluczową zaletą wybranej architektury wykorzystania pamięci jest brak konieczności kopiowania danych przesyłanych pomiędzy mikroprocesami. Ponieważ wszystkie dane są zaalokowane w jednej puli pamięci, przesyłanie wiadomości sprowadza się jedynie do przekazania wkaźników do owych wiadomości pomiędzy mikroprocesami, co jest operacją o złożoności czasowej i pamięciowej rzędu /O(1)/.

Alternatywne rozwiązania polegające na separacji danych mikroprocesów poprzez wykorzystanie osobnych puli pamięci dla każdego mikroprocesu nie posiadają tej zalety i wymagają kosztownego kopiowania wszystkich przesyłanych wiadomości, co w przypadku wzmożonej komunikacji pomiędzy mikroprocesami powoduje znaczną degradację wydajności.

Kolejną ważną zaletą wybranej architektury jest łatwość jej implementacji z wykorzystaniem sterty procesu maszyny wirtualej, zarządzanej przez system operacyjny, na którym jest ona uruchomiona. Pozwala to na wykorzystanie gotowego, standardowego interfejsu alokacji udostępnianego przez system operacyjny.

Do niewątpliwych wad zastosowanej architektury należą wyzwania, jakie stawia ona algorytmom kolekcji obiektów nieosiągalnych. Zadaniem tych algorytmów jest automatyczne zwolnienie nieużywanej pamięci mikroprocesów, co w wyniku współdzielenia danych jest znacznie utrudnione i może prowadzić do długich przerw w działaniu maszyny wirtualnej przeznaczonych na cykle kolekcji "śmieci".

Kolejną wadą architektury współdzielonej sterty jest fakt, że pamięć mikroprocesu nie może zostać od razu i w całość zwolniona po zakończeniu jego działania. Ponieważ dane mogą być wciąż wykorzystywane przez inne mikroprocesy, po zakończeniu działania jednego z nich musi zostać wykonany pełen cykl kolekcji obiektów nieosiągalnych.

Szczegółowa analiza zalet i wad architektury współdzielonej sterty w kontekście implementacji języka =Erlang= została zawarta w [[cite:Wilhelmsson2005]].

** Implementacja alokatora obiektów
Maszyna wirtualna ThesisVM wykorzystuje algorytm kaskadowych alokatorów polegający na kompozycji wielu algorytmów alokacji obiektów wraz z wykorzystywanymi przez nie metadanymi w taki sposób, by umożliwić algorytmowi na danym poziomie odwoływanie się do algorytmu na niższym poziomie. Schematyczna reprezentacja takiego rozwiązania została zawarta na rysunku [[ref:fig:tvm-alloc]].

W momencie, gdy algorytm na danym poziomie ustali, że nie jest w stanie obsłużyć żądania użytkownika przepływ sterowania zostanie przekazany do algorytmu leżącego poziom niżej, gdzie obsługa żądania będzie kontynuowana. Dzięki takiemu rozwiązaniu możliwe jest zaimplementowanie szeregu ciekawych algorytmów alokacji i dowolne ich komponowanie.

Obecnie, implementacja ThesisVM wykorzystuje dwu-poziomowy alokator składający się z algorytmów *TVM Alloc* oraz *D Alloc*, który został zaprezentowany ra rysunku [[ref:fig:tvm-alloc]].

#+begin_center
#+label: fig:tvm-alloc
#+caption: Schemat kaskadowych alokatorów wykorzystanych w ThesisVM.
#+attr_latex: scale=0.7
[[file:./img/allocator.pdf]]
#+end_center

*D Alloc* jest standardowym interfejsem alokatora języka =D=, który wykorzystuje metadane kolektora obiektów nieosiągalnych języka =D= i udostępnia wyrównaną do słowa procesora (8 bajtów na architekturze x86\_64) pamięć przezeń zarządzaną. Wybór tego algorytmu zostanie umotywowany w sekcji [[ref:sec:tvm-cycles]].

 Alternatywnym rozwiązaniem dla =D Alloc= byłoby wykorzystanie interfejsu manualnego zarządzania pamięcią poprzez wykorzystanie funkcji =malloc= i =free= ze standardowej biblioteki języka =C=, która wchodzi w skład standardowej biblioteki języka =D=.

*TVM Alloc* jest dodatkowym algorytmem alokacji zbudowanym w oparciu o interfejs =D Alloc=, który dodatkowo zapewnia buforowanie (ang. /caching/) pamięci za pomocą *listy niedawno zwolnionych obiektów*, która jest przeszukiwana w pierwszej kolejności podczas żądania alokacji.

#+begin_center
#+label: fig:tvm-gc-regs
#+caption: Schemat rejestrów wymaganych przez implementację alokatora obiektów.
#+attr_latex: scale=1.5
[[file:./img/GC.pdf]]
#+end_center

Każdy mikroproces posiada własną listę niedawno zwolnionych obiektów (rysunek [[ref:fig:tvm-gc-regs]]), co zapewnia lepsze wykorzystanie pamięci przez /zwiększenie lokalności referencji/ - obiekty zwalniane podczas działania mikroprocesu trafiają na listę niedawno zwolnionych obiektów i bardzo szybko są wykorzystywane powtórnie bez konieczności odwoływania się do alokatorów z niższych poziomów.

Wykorzystanie listy niedawno zwolnionych obiektów do buforowania alokacji umożliwia także  zaimplementowanie zupełnie nowej klasy algorytmów kolekcji obiektów nieosiągalnych w oparciu o /leniwe cykle kolekcji/. Algorytm taki został opisany w następnej sekcji.

Zagadnienie alokacji pamięci jest bardzo rozległe i w kontekście języków programowania zależy od wielu różnych czynników, takich jak charakterystyki zużycia pamięci konkretnych programów, wielkości alokowanych obiektów, czy czasy ich życia. Przegląd [[cite:Wilson1995]] zawiera szczegółową analizę wydajności wielu różnych algorytmów alokacji pamięci w warunkach symulowanych oraz dla rzeczywistych programów, co było niezastąpionym źródłem wiedzy pomocnym przy wyborze i implementacji algorytmu alokacji obiektów maszyny wirtualnej ThesisVM.

** Kolekcja obiektów nieosiągalnych
Różne podejścia do problemu automatycznego zwalniania nieużywanej pamięci zostały już opisane w sekcji [[ref:sec:tvm-heap-archs]], której konkluzją był wybór algorytmu *zliczania referencji* jako głównego algorytmu kolekcji obiektów nieosiągalnych.

Algorytm zliczania referencji polega na przechowywaniu i modyfikacji liczników aktywnych referencji wskazujących na dany obiekt w pamięci. Liczniki te przechowywane są w nagłówkach obiektów, dzięki czemu algorytm jest w stanie zdecydować, czy konkretny obiekt jest w dalszym ciągu w użyciu jedynie na podstawie wkaźnika na jego nagłówek.

Liczniki modyfikowane są podczas tworzenia nowych i usuwania istniejących referencji - stworzenie nowej referencji do konkretnego obiektu powoduje inkrementację jego licznika referencji, natomiast usunięcie istniejącej referencji powoduje jego dekrementację. W momencie, gdy wartość licznika osiągnie zero obiekt jest uznawany za /nieosiągalny/ i następuje zwolnienie jego pamięci ora usunięcie wszystkich referencji wchodzących w jego skład.

Wariant algorytmu zaimplementowany w maszynie wirtualnej ThesisVM to tak zwane *leniwe zliczanie referencji*, którego implementacja jest możliwa dzięki zastosowaniu alokatora buforującego zwalniane obiekty. Algorytm ten polega na opóźnieniu usuwania referencji wchodzących w skład usuwanego obiektu do czasu aż jego pamięć zostanie powtórnie wykorzystana.

Modyfikacja ta jest bardzo prosta i pozwala osiągnąć dużo lepsze charakterystyki czasowe kolekcji obiektów nieosiągalnych kosztem zwiększenia ogólnego zużycia pamięci - obiekty nie są zwalniane natychmiastowo, a dopiero przy następnej alokacji. Dokładne badanie wpływu opisanej modyfikacji algorytmu zliczania referencji na zużycie pamięci zostało przedstawione w [[cite:Boehm2004]].

Rysunek [[ref:fig:tvm-lazy-refcount-free]] zawiera schemat dealokacji obiektu z wykorzystaniem opisanego powyżej algorytmu.

#+begin_center
#+label: fig:tvm-lazy-refcount-free
#+caption: Schemat działania zwalniania pamięci obiektów.
#+attr_latex: scale=0.7
[[file:./img/lazyrefcountfree.pdf]]
#+end_center

Obiekt =old=, którego licznik referencji osiągnął wartość 0 w wyniku usunięcia ostatniej aktywnej referencji zostaje przeniesiony do listy niedawno zwolnionych obiektów =free=. Lista ta wykorzystuje ów licznik do przechowywania wskaźnika na następny element listy, dzięki czemu możliwe jest zachowanie danych obiektu bez zmian w celu późniejszego, leniwego ich usunięcia podczas następnej alokacji (rysunek [[ref:fig:tvm-lazy-refcount-alloc]]).

Alokacja nowego obiektu =new= polega na pobraniu pierwszego elementu listy niedawno zwolnionych obiektów =free= oraz usunięciu wszystkich referencji wchodzących w jego skład. Pociąga to za sobą dekrementację liczników referencji obiektów, na które owe referencje wskazują i ewentualną dealokację tych obiektów, jeśli ich liczniki osiągnęły wartość 0. W przypadku, gdy lista =free= jest pusta tworzony jest zupełnie nowy obiekt, który jest dodawany do wspólnej puli pamięci.

W przypadku języków programowania wspierających przetwarzanie współbieżne algorytm dodatkowo komplikuje konieczność wykorzystywania /operacji atomowych/ na licznikach referencji obiektów, które mogą być modyfikowane jednocześnie przez wiele wątków sprzętowego procesora. Dodatkowo ważne jest wykorzystanie /barier pamięci/, które uniemożliwiają zmiany kolejności wykonywania operacji na pamięci, co jest częstym zabiegiem optymalizacyjnym w nowoczesnych procesorach.

#+begin_center
#+label: fig:tvm-lazy-refcount-alloc
#+caption: Schemat działania alokacji pamięci nowych obiektów.
#+attr_latex: scale=0.7
[[file:./img/lazyrefcountalloc.pdf]]
#+end_center

Konieczność stosowania operacji atomowych i barier pamięci powoduje nieznaczny spadek wydajności maszyny wirtualnej, który jednak jest wart odnotowania. Implementacja kolektora "śmieci" ThesisVM wykorzystuje wbudowane w język =D= kwalifikatory typów =shared=, które gwarantują stosowanie operacji atomowych i barier pamięci w stategicznych miejscach.

Implementacja optymalizuje także modyfikacje liczników referencji przez ich opóźnienie lub całkowite wyeliminowanie (arg. /deferred reference counting/), jeśli nie są konieczne - na przykład w przypadku transferu referencji pomiędzy dwoma obiektami.

Jest to potencjalnie niebezpieczna technika wymagająca manualnego dekrementowania i inkrementowania liczników referencji za pomocą funkcji =use= oraz =free=. Alternatywnym rozwiązaniem jest wykorzystanie inteligentnych wskaźników (ang /smart pointers/), które gwarantują deterministyczną inkrementację i dekrementację liczników.

Więcej możliwych usprawnień algorytmu kolekcji obiektow nieosiągalnych za pomocą zliczania referencji zostało przedstawionych w [[cite:Bacon2004]] oraz [[cite:Shahriyar2012]].

** Kolekcja obiektów cyklicznych
#+latex: \label{sec:tvm-cycles}

Dużą wadą kolektorów zliczających referencje jest ich słabe wsparcie dla zwalniania pamięci struktur cyklicznych, które nie są dłużej użytkowane w programie. Sytuacja ta ma miejsce, gdy pewna struktura danych zawiera referencje do siebie samej, co w efekcie uniemożliwia jej dealokację, ponieważ jej licznik referencji nigdy nie osiąga wartości zerowej.

W maszynie wirtualnej ThesisVM problem ten objawia się przy wykorzystywaniu wbudowanego operatora =self=, który zwraca referencję na obecnie działający mikroproces. Referencja ta może zostać zapisana w stanie procesu efektywnie tworząc cykl i uniemożliwiając kolekcję danych procesu po zakończeniu jego działania.

Aby temu zaradzić implementacja alokatora wykorzystuje wbudowany w język =D= kolektor śledzący, który jest uruchamiany co pewien interwał w celu dealokacji struktur cyklicznych, takich jak mikroprocesy referujące same siebie.

Implementacja alokatora jest jednak na tyle generyczna, by umożliwić w przyszłości zaimplementowanie alternatywnego, zapasowego kolektora śledzącego, który w przeciwieństwie do kolektora języka =D= mógłby wykorzystywać dane o typach obiektów ThesisVM w celu prowadzenia precyzyjniejszych i szybszych kolekcji.

* Model przetwarzania współbieżnego
#+latex: \label{sec:tvm-smp}

- Opisać bardziej szczegółowo model SMP.

- Opisać bardziej szczegółowo Model Aktorowy i asynchroniczne przekazywanie wiadomości. [[cite:Hewitt1973,Clinger1981]]

** Implementacja symetrycznego multiprocessingu
- Opisać bardziej szczegółowo implementację SMP

#+begin_center
#+label: ref:tvm-smp
#+caption: Schemat symetrycznego multiprocesora ThesisVM.
#+attr_latex: scale=1.0
[[file:./img/SMP.pdf]]
#+end_center

- Co SMP robi podczas interpretacji kodu.
- Opisać wiadomości kontrolne.

** Harmonogramowanie procesów
#+latex: \label{sec:tvm-scheduling}

- Opisać algorytm Completely Fair Scheduler. [[cite:Pabla2009]]

#+begin_center
#+label: ref:tvm-scheduler-regs
#+caption: Schemat rejestrów wymaganych przez usprawnienia hanmonogramowania SMP.
#+attr_latex: scale=1.5
[[file:./img/Scheduler.pdf]]
#+end_center

- Opisać implementację i wykorzystanie RUNq.

- Opisać implementację prymitywu =sleep= oraz WAITq.

- Opisać wady możliwe usprawnienia (load-balancing i dzielenie zużycia).

** Implementacja Modelu Aktorowego
- Opisać powstawanie procesów i prymityw =spawn=.

- Opisać implementację prymitywów =send= oraz =recv=.

- Opisać logiczną autonomiczność procesów (brak mutacji = inne procesy nie mogą ingerować).

- Opisać sposób porozumiewania się procesów (kolejki nieblokujące). [[cite:MichaelScott1996,Herlihy2002]]

#+begin_center
#+label: ref:tvm-actor-regs
#+caption: Schemat rejestrów wymaganych przez implementację Modelu Aktorowego.
#+attr_latex: scale=1.5
[[file:./img/Actor.pdf]]
#+end_center

- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).

** Implementacja przesyłania wiadomości

- Opisać implementację kolejek nieblokujących (+ weryfikacja poprawności). [[cite:MichaelScott1996,Groves2008]]
- Opisać wykorzystanie CAS i problem ABA.

#+begin_center
#+label: ref:tvm-msgs
#+caption: Schemat działania przesyłania wiadomości.
#+attr_latex: scale=1.2
[[file:./img/messagepassing.pdf]]
#+end_center

- Opisać krótko wady i możliwe usprawnienia zastosowanego rozwiązania (dynamic size, wait-free, optimistic FIFO). [[cite:Herlihy2002,Kogan2011,Ladan-Mozes2004]]

- Opisać krótko alternatywne podejścia (synchroniczne przekazywanie wiadomości - kanały, locki/mutexy/semafory).

- Opisać sposób pobierania wiadomości z kolejki i jego możliwe usprawnienia (pattern-matching).

* COMMENT Podsumowanie
#+latex: \label{sec:conclusion}

- Opisać co udało się zrobić.
- Opisać czego nie udało się zrobić (+ możliwe usprawnienia).

** Interpreter kodu bajtowego
- Opisać brak apdejtowania już obliczonych wartości i dać link do sec:future-development.
- Opisać możliwość zastosowania lepszej reprezentacji bytecodu i bytecode threading.

** Kolektor obiektów nieosiągalnych
- Przeanalizować szybkość, pauzy, zużycie pamięci.

** Przetwarzanie współbieżne
- Przeanalizować szybkość przesyłania wiadomości/konieczność czekania procesów, wielkość kolejek wiadomości.

** Kierunki przyszłego rozwoju
#+latex: \label{sec:future-development}

- Opisać plany na przyszły rozwój projektu (priorytet procesów, load balancing SMP, wsparcie dla =Core Erlang=, bytecode threading, przebiegi optymalizacyjne podczas kompilacji, umożliwienie dystrybucji na wiele maszyn, zapasowy kolektor śmieci cyklicznych, opcja wykorzystania sterty prywatnej i autonomicznego alokatora, natywna kompilacja JIT, wektory, data-level parallelism, optymalizacja wykorzystania stosu, hardłerowa implementacja interpretera kodu bajtowego).

# The bibliography
#+begin_latex
\bibliographystyle{ieeetr}
\bibliography{bibs}
#+end_latex

#+latex: \appendix
* COMMENT Przykładowe programy
#+latex: \label{sec:tvm-samples}

** Interfejs i użytkowanie ThesisVM
- Opisać sposób uruchamiania maszyny wirtualnej.

** "Hello world!"
** Funkcje i operacje prymitywne
** Factorial
** Fibonacci
** Współbieżne "Hello world!"
** Współbieżne obliczanie silni

* COMMENT Spisy wbudowanych operatorów i funkcji
#+latex: \label{sec:tvm-primops}

#+begin_latex
{\Large\noindent\textbf{Spis operatorów wbudowanych}}
#+end_latex

- =+= - pobiera dwa parametry typu numerycznego i zwraca wynik ich dodawania.
- =-= - pobiera dwa parametry typu numerycznego i zwraca wynik ich odejmowania.
- =*= - pobiera dwa parametry typu numerycznego i zwraca wynik ich mnożenia.
- =/= - pobiera dwa parametry typu numerycznego i zwraca wynik ich dzielenia.
- =mod= - pobiera dwa parametry typu numerycznego i zwraca wynik przeprowadzenia na nich operacji modulo.
- =pow= - pobiera dwa parametry typu numerycznego i zwraca wynik przeprowadzenia na nich operacji potęgowania.
- =inc= - pobiera jeden parametr typu numerycznego i zwraca jego wartość inkrementowaną o 1.
- =dec= - pobiera jeden parametr typu numerycznego i zwraca jego wartość dekrementowaną o 1.
- $=$ - pobiera dwa parametry typu numerycznego i zwraca 1 w przypadku, gdy są równe, lub pustą listę w przeciwnym przypadku.
- =<= - pobiera dwa parametry typu numerycznego i zwraca 1 w przypadku, gdy pierwszy z nich ma mniejszą wartość od drugiego, lub pustą listę w przeciwnym przypadku.
- =>= - pobiera dwa parametry typu numerycznego i zwraca 1 w przypadku, gdy pierwszy z nich ma większą wartość od drugiego, lub pustą listę w przeciwnym przypadku.
- =<== - pobiera dwa parametry typu numerycznego i zwraca 1 w przypadku, gdy pierwszy z nich ma mniejszą bądź równą wartość od drugiego, lub pustą listę w przeciwnym przypadku.
- =>== - pobiera dwa parametry typu numerycznego i zwraca 1 w przypadku, gdy pierwszy z nich ma większą bądź równą wartość od drugiego, lub pustą listę w przeciwnym przypadku.
- =null?= - pobiera jeden parametr dowolnego typu i zwraca 1 w przypadku, gdy jest on pustą listą, lub pustą listę w przeciwnym przypadku.
- =null= - nie pobiera żadnych parametrów, zwraca pustą listę.
- =cons= - pobiera dwa parametry dowolnych typów i zwraca parę składającą się z obu pobranych wartości.
- =car= - pobiera jeden parametr, który musi być parą i zwraca pierwszy jej element.
- =cdr= - pobiera jeden parametr, który musi być parą i zwraca drugi jej element.
- =typeof= - pobiera jeden parametr dowolnego typu i zwraca wartość liczbową identyfikującą jego typ.
- =sleep= - pobiera jeden parametr typu numerycznego i usypia mikroproces na taką ilość milisekund, zwraca ilość milisekund, na które mikroproces został uśpiony.
- =print= - pobiera jeden parametr dowolnego typu i wyświetla jego tekstową reprezentację, zwraca parametr.
- =self= - nie pobiera parametrów, zwraca deskryptor obecnie działającego mikroprocesu.
- =send= - pobiera dwa parametry, z których pierwszy musi być deskryptorem mikroprocesu, wysyła drugi parametr jako wiadomość do mikroprocesu z pierwszego parametru.
- =recv= - pobiera jeden parametr typu numerycznego, sprawdza, czy w kolejce wiadomości mikroprocesu znajduje się wiadomość i ją zwraca; jeśli w kolejce wiadomości mikroprocesu nie znajdują się żadne wiadomości zwraca pustą listę i usypia mikroproces na czas przekazany w parametrze.

#+begin_latex
\pagebreak
\vspace*{2cm}
{\Large\noindent\textbf{Spis funkcji wbudowanych}}
#+end_latex

- =not= - przyjmuje jeden parametr i zwraca jego logiczną negację (1 w przypadku logicznej prawdy i pustą listę w przypadku logicznego fałszu).
- =and= - przyjmuje dwa parametry i zwraca ich logiczną koniunkcję; funkcja ta mogła zostać zaimplementowana dzięki leniwej naturze maszyny wirtualnej ThesisVM.
- =or= - przyjmuje dwa parametry i zwraca ich logiczną alternatywę; funkcja ta mogła zostać zaimplementowana dzięki leniwej naturze maszyny wirtualnej ThesisVM.

#+latex: \noindent
Dodatkowo wszystkie prymitywne operatory wymienione w powyższej liście mają swoje odpowiedniki funkcyjne o takiej samej nazwie i semantyce.

* COMMENT Spisy rysunków i fragmentów kodu
#+latex: \label{sec:misc}

#+begin_latex
\begingroup
  \renewcommand*{\addvspace}[1]{}
  \listoffigures
  \pagebreak
  \listofmylisting
%  \listoftables
\endgroup
#+end_latex
