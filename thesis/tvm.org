################################################################################
#+TITLE: ThesisVM BEng
#+AUTHOR: Kajetan Rzepecki
#+DATE: 2013
#
#+BEGIN_OPTIONS
#+BIND: org-export-latex-title-command ""
#+STARTUP: content
#+LaTeX_CLASS: aghdpl
#+LaTeX_CLASS_OPTIONS: [a4paper, 12pt]
#+LaTeX_HEADER: \usepackage[polish]{babel}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{multicol}
#+LATEX_HEADER: \usepackage[nottoc, notlof, notlot]{tocbibind}
#+OPTIONS: tags:nil, todo:nil, toc:nil, date:nil
#+END_OPTIONS
####################

# Helpers & Stuff
#+begin_src emacs-lisp :exports none
  (add-to-list 'org-export-latex-classes
               '("aghdpl"
                 "\\documentclass{aghdpl}"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")
                 ))
  (setq org-export-latex-classes (cdr org-export-latex-classes))
#+end_src

# AGH setup:
#+BEGIN_OPTIONS
#+LATEX_HEADER: \shortauthor{K. Rzepecki}
#+LATEX_HEADER: \degreeprogramme{Informatyka}

#+LATEX_HEADER: \thesistype{Praca dyplomowa inżynierska}

#+LATEX_HEADER: \titlePL{Implementacja maszyny wirtualnej dla funkcyjnych języków programowania wspierających przetwarzanie współbieżne.}
#+LATEX_HEADER: \titleEN{Implementation of a virtual machine for functional programming languages with support for concurrent computing.}

#+LATEX_HEADER: \shorttitlePL{Implementacja maszyny wirtualnej dla funkcyjnych języków programowania \dots}
#+LATEX_HEADER: \shorttitleEN{Implementation of a virtual machine for functional programming languages \dots}

#+LATEX_HEADER: \supervisor{dr inż. Piotr Matyasik}

#+LATEX_HEADER: \department{Katedra Informatyki Stosowanej}

#+LATEX_HEADER: \faculty{Wydział Elektrotechniki, Automatyki,\protect\\[-1mm] Informatyki i Inżynierii Biomedycznej}

##+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję opiekunowi pracy za wsparcie merytoryczne oraz dobre rady edytorskie pomocne w tworzeniu pracy.}
#+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję Lucynie za cierpliwość i wsparcie podczas tworzenia pracy.}
#+END_OPTIONS

# Title pages & table of contents:
#+begin_latex
\titlepages
\tableofcontents
#+end_latex

# List of Listings specific:
#+begin_latex
\newcommand{\listlistingname}{\bfseries\Large{Spis listingów}}
\newlistof[chapter]{mylisting}{mlol}{\listlistingname}
\newcommand{\mylisting}[1]{%
  \refstepcounter{mylisting}%
  #1%
  \addcontentsline{mlol}{figure}
    {\protect\numberline{\thechapter.\thelisting}#1}\par%
}
\renewcommand{\cftbeforemloltitleskip}{20mm}
\renewcommand{\cftaftermloltitleskip}{5mm}
#+end_latex

* Wstęp
#+latex: \label{sec:intro}

Tematem pracy jest implementacja /maszyny wirtualnej/ dla funkcyjnych języków programowania wspierających /przetwarzanie współbieżne/.

Maszyna wirtualna jest warstwą abstrakcji leżącą pomiędzy programem a rzeczywistym sprzętem, która pozwala uniezależnić ów program od rozbieżności w działaniu różnych architektur komputerów. Wystarczy zaimplementować maszynę wirtualną dla danej architektury rzeczywistego sprzętu by umożliwić uruchamianie na niej wszystkich kompatybilnych z programów. Rysunek [[ref:fig:vm-arch]] prezentuje uproszczony schemat takiego rozwiązania - programy docelowe zostają skompilowane do /kodu bajtowego/ akceptowanego przez maszynę wirtualną a dopiero ów bajtkod jest przez nią uruchamiany.

#+begin_center
#+label: fig:vm-arch
#+caption: Schemat interakcji z Maszyną Wirtualną.
#+attr_latex: scale=0.7
[[file:./img/fullarch.pdf]]
#+end_center

Przetwarzanie współbieżne opiera się o współistnienie wielu procesów, które konkurują o dostęp do współdzielonych zasobów. W kontekście pracy, przetwarzanie współbieżne jest rozumiane jako asynchroniczne przekazywanie wiadomości pomiędzy działającymi, autonomicznymi procesami, czyli jako Model Aktorowy [[cite:Hewitt1973,Clinger1981]].

Celem pracy jest stworzenie interpretera kodu bajtowego zdolnego uruchamiać kod skompilowanych programów, kolektora obiektów nieosiągalnych umożliwiającego automatyczne zarządzanie pamięcią oraz architektury symetrycznego multiprocesora (SMP) zapewniającego rzeczywistą współbieżność uruchamianych programów w oparciu o Model Aktorowy.
Językiem implementacji projektu jest język =D= (w wersji 2.0 opisanej w [[cite:Alexandrescu2010]]), stosunkowo nowoczesny, kompilowany do kodu maszynowego następca języka =C++=.

** Motywacja pracy
#+latex: \label{sec:thesis-motivation}

Motywacją powstania pracy są problemy napotkane podczas użytkowania języka =Erlang= [[cite:Armstrong1996]], dotyczące wydajności przesyłania wiadomości średniego rozmiaru w obecnej, standardowej jego implementacji. Problemy owe zilustrowano na listingu [[ref:code:erlang-problem]].

Zaprezentowany fragment kodu odczytuje plik w formacie JSON, który następnie jest dekodowany do wewnętrznej reprezentacji posiadającej skomplikowaną strukturę, by ostatecznie został on wysłany do dużej liczby współbieżnie działających procesów celem dalszego przetwarzania (linia [[ref:line:bad]]). Rozwiązanie takie powoduje znaczący spadek wydajności.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Fragment kodu prezentujący problem występujący w języku \texttt{Erlang}.}}
#+latex: \label{code:erlang-problem}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src erlang
  start() ->
      Data = file:read("file.json"),    %% <<"Dane ...">>
      transmogrify(Data).
  
  transmogrify(Data) ->
      Pids = framework:spawn_bajilion_procs(fun do_stuff/1),
      JSON = json:decode(Data),         %% {[Dane ...]}
      framework:map_reduce(Pids, JSON). %% !#&^@ $\label{line:bad}$
  
  do_stuff(JSON) ->
      %% Operacje na danych.
      result.
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Język =Erlang= wykorzystuje skomplikowaną architekturę pamięci, która w różny sposób traktuje obiekty różnego typu. Większość obiektów, w szczególności skomplikowana strukturalnie reprezentacja danych w formacie JSON, przechowywana jest w prywatnych stertach każdego procesu i musi być kopiowana podczas przesyłania jej w wiadomościach pomiędzy nimi. Reguła ta nie dotyczy danych binarnych, w szczególności danych odczytanych z pliku, ponieważ te korzystają z innych algorytmów nie wymagających kopiowania kosztem większego zużycia pamięci.

W związku z tym, aby zaradzić problemowi opisanemu powyżej, wystarczy przenieść operację dekodowania danych odczytanych z pliku bezpośrednio do procesów na nich operujących (listing [[ref:code:erlang-solution]]).
W nowej wersji procesy przesyłają jedynie dane binarne, które nie wymagają kopiowania pamięci, a narzut wydajności spowodowany wielokrotnym ich dekodowaniem jest niższy niż ten spowodowany nadmiernym kopiowianiem. W efekcie, kod działa wydajniej, kosztem logiki przepływu danych i organizacji modułów.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Suboptymalne rozwiązanie problemu w języku \texttt{Erlang}.}}
#+latex: \label{code:erlang-solution}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true"))
#+begin_src erlang
  transmogrify(Data) ->
      Pids = framework:spawn_bajilion_procs(fun do_stuff/1),
      framework:map_reduce(Pids, Data).
  
  do_stuff(Data) ->             %% <<"Dane ...">>
      JSON = json:decode(Data), %% {[Dane ...]} * bazylion
      %% Operacje na danych.
      result.
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Celem pracy jest uniknięcie problemu nadmiernego kopiowania pamięci przez wybranie odpowiedniego modelu pamięci i implementację algorytmów kolekcji obiektow nieosiągalnych, które umożliwiają przesyłanie wiadomości pomiędzy procesami bez konieczności kopiowania ich zawartości.

** Zawartość pracy
W skład pracy wchodzi implementacja interpretera kodu bajtowego, kolektora obiektów nieosiągalnych oraz symetrycznego multiprocesora (SMP).

Sekcja [[ref:sec:intro]] opisuje cele, motywację, zakres oraz zawartość pracy.

Sekcja [[ref:sec:tvm-arch]] przybliża architekturę maszyny wirtualnej ThesisVM zaimplementowanej w ramach pracy, zaczynając od reprezentacji pośredniej programów (TVMIR) i jej kompilacji do kodu bajtowego, przez interpretację kodu bajtowego i zarządzanie pamięcią do projektu przetwarzania współbieżnego.

Sekcja [[ref:sec:tvm-vm]] szczegółowo opisuje implementację interpretera kodu bajtowego maszyny wirtualnej ThesisVM. Zaprezentowane zostają reprezentacje różnych obiektów, na których operuje maszyna, implementacja wpudowanych operatorów i funkcji prymitywnych oraz reprezentacja i generowanie kodu bajtowego akceptowanego przez interpreter.

Sekcja [[ref:sec:tvm-gc]] szczegółowo prezentuje implementację wybranego modelu pamięci, alokatora nowych obiektów oraz kolektora obiektów nieosiągalnych.

Sekcja [[ref:sec:tvm-smp]] szczegółowo opisuje implementację asynchronicznego przekazywania wiadomości i symetrycznego multiprocesora w maszynie ThesisVM. Zaprezentowana zostaje implementacja Modelu Aktorowego i harmonogramowania procesów.

Sekcja [[ref:sec:conclusion]] zawiera podsumowanie pracy oraz zarys możliwych kierunków dalszego rozwoju projektu.

Dodatki [[ref:sec:tvm-samples]], [[ref:sec:tvm-primops]] i [[ref:sec:misc]] zawierają odpowiednio wskazówki użytkowania ThesisVM i przykładowe programy gotowe do uruchomienia na maszynie wirtualnej, spis wbudowanych operatorów i funkcji prymitywnych oraz spisy rysunków, tablic i fragmentów kodu znajdujących się w tekście pracy.

* Architektura ThesisVM
#+latex: \label{sec:tvm-arch}

Ninejsza sekcja opisuje architekturę maszyny wirtualnej ThesisVM powstałej na potrzeby pracy oraz języka przez nią akceptowanego.

Rysunek [[ref:fig:tvm-arch]] zawiera schematyczną reprezentację maszyny wirtualnej ThesisVM uwzględniającą architekturę procesora sprzętu, na którym działa system operacyjny oraz sama maszyna wirtualna. Na schemacie widać poszczególne podsystemy ThesisVM, takie jak autonomiczne procesy (zwane dalej /mikroprocesami/, =µProcN=), czy symetryczne multiprocesory (zwane dalej =SMPn=).

Mikroprocesy są przypisane do symetrycznych multiprocesorów w stosunku wiele-do-jednego, to znaczy każdy mikroproces jest przypisany do dokładnie jednego symetrycznego multiprocesora, który natomiast może zarządzać zbiorem wielu mikroprocesów.

#+begin_center
#+label: fig:tvm-arch
#+caption: Architektura maszyny wirtualnej ThesisVM.
#+attr_latex: scale=1.0
[[file:./img/arch.pdf]]
#+end_center

Każdy symetryczny multiprocesor działa w osobnym wątku procesora sprzętowego, zapewniając rzeczywistą współbieżność. Wszystkie =SMPn= są takie same i wykonują takie same zadania, czyli harmonogramowanie i wywłaszczanie mikroprocesów, a różni je jedynie stan, w którym się znajdują oraz zbiór procesów, którymi zarządzają.
Na schemacie widnieje mapowanie jeden-do-jednego pomiędzy rdzeniami procesora (=CPUn=) a poszczególnymi =SMPn=, nie jest to jednak wymóg konieczny i zależy od konfiguracji maszyny wirtualnej. Konfigurowalna ilość równocześnie działających SMP pomaga osiągnąć lepszą skalowalność maszyny wirtualnej i może być zmieniana dynamicznie wedle potrzeb.

Pozostając w zgodzie ze schematem przedstawionym na rysunku [[ref:fig:vm-arch]], interakcja z maszyną ThesisVM przebiega w analogiczny sposób. Kod programów w reprezentacji pośredniej (TVMIR) jest kompilowany do kodu bajtowego akceptowanego przez maszynę wirtualną, która następnie go ładuje i wykonuje umożliwiając zrównoleglenie obliczeń poprzez tworzenie nowych procesów i przesyłanie pomiędzy nimi wiadomości.

** Reprezentacja pośrednia programów
ThesisVM wykorzystuje prostą reprezentację pośrednią programów w postaci TVMIR - języka lisp'owego z rodziny =Scheme= [[cite:Abelson1996]], który jest dostatecznie ekspresywny, by można w nim było zapisać nietrywialne algorytmy, a jednocześnie na tyle prosty, by ułatwić jego późniejszą kompilację do kodu bajtowego akceptowanego przez maszynę wirtualną.

Języki pośrednie reprezentacji programów są często stosowane w implementacjach wielu maszyn wirtualnych, takich jak ParrotVM, czy CoreVM [[cite:PeytonJones1992]], a także w implementacjach kompilatorów kodu maszynowego wielu języków programowania (na przykład GCC, LLVM). Reprezentacje pośrednie mają wiele zalet, począwszy od ułatwienia wsparcia dla szerszej gamy języków wysokiego poziomu, na możliwości tworzenia wygodnych założeń dodatkowych kończąc.

Na listingu [[ref:code:tvmir]] spisana w formacie BNF została gramatyka języka reprezentacji pośredniej wykorzystanego w maszynie wirtualnej ThesisVM. Gramatyka ta jest nieskomplikowana i w dużej mierze przypomina gramatiki różnych dialektów języka =Lisp=.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Gramatyka języka TVMIR.}}
#+latex: \label{code:tvmir}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
# TODO Add primop, apply, send, receive and spawn.
#+begin_src xml
  <program>        ::= <definitions>
  <definitions>    ::= <definition> <definitions> | ''
  <definition>     ::= '(' 'define' '(' <symbol> <arguments> ')'
                                    <expression> ')'
  <arguments>      ::= <symbol> <arguments> | ''
  <expression>     ::= <value> | <application> | <primop>
                     | <conditional> | <quote> | <spawn>
  <value>          ::= <list> | <symbol> | <number>
  <application>    ::= '(' <expression> <expressions> ')'
  <expressions>    ::= <exrpession> <exrpessions> | ''
  <conditional>    ::= '(' 'if' <expression>
                                <expression>
                                <expression> ')'
  <quote>          ::= ''' <expression> | '(' 'quote' <epression> ')'
  <spawn>          ::= '(' 'spawn' <symbol> <expression> ')'
  <primop>         ::= '(' 'primop' <symbol> <expressions> ')'
  <list>           ::= '(' <expressions> ')'
  <symbol>         ::= <literal-string> | <atom>
  <literal-string> ::= '"' "Dowolny literał znakowy." '"'
  <atom>           ::= "Dowolny literał znakowy bez znaków białych."
  <number>         ::= "Dowolny literał liczbowy."
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Języki z rodziny =Lisp= są bardzo wygodnym medium dla pośredniej reprezentacji programów ponieważ przedstawiają one drzewo syntaktyczne analizowanego kodu programu i nie wymagają skomplikowanego algorytmu parsowania. Dodatkowo, homoikoniczność tych języków może pomóc w tworzeniu narzędzi służących do przetwarzania kodu rozpatrywanego języka (w szczególności kompilatorów) bezpośrednio w rozpatrywanym języku. Temat ten został dogłębnie zbadany w [[cite:Abelson1996]]. Dodatek [[ref:sec:tvm-samples]] zawiera przykłady kodu w języku pośredniej reprezentacji programów TVMIR.

Język reprezentacji pośredniej przedstawiony w pracy wymaga stworzenia kilku założeń dodatkowych dotyczących transformacji kodu. Najważniejszym z nich jest konieczność przeprowadzenia operacji lambda-unoszenia (ang. /lambda lifting/), opisanej bardzo dokładnie w [[cite:PeytonJones1992]], której efekt zaprezentowano na listingu [[ref:code:lambda-lifting]].

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Fragmenty kodu prezentujące operację lambda-unoszenia.}}
#+latex: \label{code:lambda-lifting}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))

#+latex: \begin{multicols}{2}
#+begin_src scheme
  ;; Przed lambda-unoszeniem:
  (define (make-adder n)
    (lambda (x)
      (+ x n)))
#+end_src

#+latex: \columnbreak
#+begin_src scheme
  ;; Po lambda-unoszeniu:
  (define (__make-adder_lambda0 n x)
    (+ x n))
  
  (define (make-adder n)
    (__make-adder_lambda n))
#+end_src
#+latex: \end{multicols}

#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Lambda-unoszenie polega na transformacji ciał funkcji w taki sposób, by tworzone w nich funkcje anonimowe zostały przeniesione na poziom główny zasięgu nazw (ang. /top-level scope/) dzięki czemu do ich implementacji wystarczy jedynie częściowa aplikacja funkcji. Na drugiej części listingu [[ref:code:lambda-lifting]] funkcja =make-adder= zwracająca anonimową funkcję została transformowana na dwie funkcje, z których =make-adder= pozostaje funkcją unarną, która korzysta z częściowej aplikacji funkcji binarnej =__make-adder_lambda0= wykonującej operację dodawania.

Pełna i poprawna implementacja operacji lambda-unoszenia jest skomplikowana, toteż nie została zawarta w dołączonym do projektu kompilatorze kodu bajtowego i musi zostać wykonana ręcznie.

Język pośredniej reprezentacji programów zastosowany w maszynie wirtualnej ThesisVM jest bardzo podobny do języka =Core Lang= wykorzystywanego w [[cite:PeytonJones1992]], jednak nie wspiera on niektórych jego konstrukcji, takich jak =let(rec)=, czy definicje dowolnych obiektów złożonych. Z drugiej strony wspiera on konstrukcje związane z Modelem Aktorowym (=receive=, =send= oraz =spawn=) oraz jest w stanie emulować brakujące konstrukcje odpowiednio przez wykorzystanie transformacji kodu połączonej z lambda-unoszeniem (listing [[ref:code:poor-mans-let]]) oraz "tagowania" list (przechowywania informacji o typie obiektu w pierwszym elemencie listy enkodującej ten obiekt).

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Ograniczona implementacja konstrukcji \texttt{let}.}}
#+latex: \label{code:poor-mans-let}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))

#+latex: \begin{multicols}{2}
#+begin_src scheme
  ;; Przed transformacją:
  (define (function x)
    (let ((value (* 2 x)))
      (* value value)))

  ;; Po transformacji:
  (define (function x)
    ((lambda (value)
       (* value value))
     (* 2 x)))
#+end_src

#+latex: \columnbreak
#+begin_src scheme
  ;; Po lambda-unoszeniu:
  (define (__function_lambda0 value)
    (* value value))

  (define (function x)
    (__function_lambda0 (* 2 x)))
#+end_src
#+latex: \end{multicols}

#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Kolejnym podobnym językiem reprezentacji pośredniej jest =Core Erlang= [[cite:Carlsson2001]] wykorzystywany w standardowej implementacji języka =Erlang=. TVMIR jest bardzo okrojoną wersją języka =Core Erlang=, pozbawioną elementów dopasowywania wzorców, która jednak wspiera pozostałe ważne jego elementy, takie jak konstrukcje odpowiedzialne za tworzenie procesów oraz przesyłanie i odbieranie wiadomości.
Istnieje możliwość rozszerzenia funkcjonalności TVMIR celem wsparcia pełnej specyfikacji =Core Erlang= [[cite:Carlsson2004]], jednak jest to poza zakresem pracy. Więcej informacji o przyszłych kierunkach rozwoju projektu zostało zawarte w sekcji [[ref:sec:future-development]].

** Kompilacja kodu bajtowego

Język pośredniej reprezentacji programów jest wygodnym medium do zapisu algorytmów, jednak wymaga on uprzedniego skompilowania do kodu bajtowego, który jest akceptowany przez maszynę wirtualną ThesisVM.

Ponieważ kompilacja kodu nie jest /stricte/ tematem pracy, mniej ważne szczegóły implementacji zostały pominięte, a niniejsza sekcja zarysowuje poszczególne fazy kompilacji kodu bajtowego ThesisVM.

Rysunek [[ref:fig:tvm-compiler-pipeline]] zawiera schemat działania kompilatora kodu bajtowego ThesisVM wraz z przykładami pośrednich reprezentacji kompilowanego kodu w poszczególnych fazach kompilacji.

#+begin_center
#+label: fig:tvm-compiler-pipeline
#+caption: Schemat potokowega działania kompilatora kodu bajtowego ThesisVM wraz ze przykładami reprezentacji danych poszczególnych faz kompilacji.
#+attr_latex: scale=0.5
[[file:./img/pipeline.pdf]]
#+end_center

Kompilator został zaimplementowany w sposób /potokowy/, to znaczy poszczególne fazy są logicznie odseparowane od siebie i wykonywane jedna po drugiej. Dzięki zastosowaniu leniwych konstrukcji języka =D= [[cite:Alexandrescu2010]] wszystkie te fazy odbywają się /jednocześnie/ i /na rządanie/ a w przypadku wykrycia błędu w danej fazie poprzednie fazy natychmiastowo się kończą, bez konieczności przetworzenia całego zestawu danych, które otrzymały na wejściu.

Pierwszą fazą jest faza analizy leksykalnej, której zadaniem jest przetworzenie /strumienia znaków/ kodu źródłowego programu w pośredniej reprezentacji TVMIR do /strumienia tokenów/, czyli elementarnych ciągów znaków będących leksemami języka. Faza ta przeprowadza także walidację składni na poziomie tokenów oraz filtrację niepotrzebnych tokenów (takich jak znaki białe, które nie mają znaczenia w TVMIR).

Drugą fazą jest faza analizy syntaktycznej, której zadaniem jest przetworzenie powstającego leniwie /strumienia tokenów/ na /wstępne drzewo parsowania/ składające się z prymitywnych konstrukcji języka TVMIR, takich jak listy, symbole i liczby. Faza ta waliduje składnię na poziomie zaawansowanych konstrukcji języka, które dzięki jego homoikoniczności zbudowane są z prymitywniejszych jego konstrukcji.

Trzecią fazą jest faza analizy semantycznej, której zadaniem jest przetworzenie /wstępnego drzewa parsowania/ na bardziej abstrakcyjne /drzewo składniowe/ (ang. /Abstract Syntax Tree/, /AST/) składające się semantycznie znaczących węzłów, takich jak aplikacja funkcji, wywołania operatorów wbudowanych, czy odwołania do zmiennych. Faza ta waliduje kod na poziomie semantycznym, sprawdzając poprawność wykorzystania różnych konstrukcji języka TVMIR.

Czwartą fazą jest faza optymalizacji, której zadaniem jest transformacja /drzewa składniowego/ powstałego w poprzedniej fazie do jego ekwiwalentu działającego szybciej po skompilowaniu. Faza ta obecnie nie wykonuje żadnych interesujących transformacji, jednak istnieje możliwość rozszerzenia jej funkcjonalności w przyszłości (opisane krótko w sekcji [[ref:sec:future-development]]).

Ostatnią, piątą fazą kompilacji jest faza generacji kodu bajtowego akceptowanego przez ThesisVM. Zadaniem tej fazy jest przetworzenie /drzewa składniowego/ do /strumienia kodu bajtowego/ za pomocą reguł kompilacji zgodnych z wybranym modelem maszyny wirtualnej (opisane szczegółowo w sekcji [[ref:sec:tvm-codegen]]).

** Interpretacja kodu bajtowego
Istnieje wiele różnych modeli maszyn wirtualnych cechujących się różnymi architekturami interpreterów kodu bajtowego, czy nawet stopniem abstrakcyjności (tak zwane maszyny abstrakcyjne).

Pod względem architektury interpretera kodu bajtowego można wyróżnić trzy główne architektury maszyn wirtualnych:

- architekturę *stosową*, korzystającą ekskluzywnie z jednego lub wielu stosów podczas przetwarzania danych, która charakteryzuje się krótkimi, pod względem zajmowanej pamięci, instrukcjami;

- architekturę *rejestrową*, korzystającą ekskluzywnie z wielu rejestrów podczas przetwarzania danych, która charakteryzuje się instrukcjami przyjmującymi wiele argumentów określających adresy rejestrów maszyny;

- architektury *hybrydowe*, łączące dwa powyższe rozwiązania w różnym stopniu.

Pod względem abstrakcyjności maszyny wirtualne można podzielić na dwie główne grupy:

- *niskopoziomowe*, do których należą maszyny implementujące wyżej wymienione architektury; główną cechą maszyn niskopoziomowych jest obecność stosunkowo nieskomplikowanego kodu bajtowego, który jest przez maszynę interpretowany podczas jej działania;

- *wysokopoziomowe*, które wymagają niestandardowego traktowania kodu programów; na przykład maszyna redukcji grafowych G-machine wykorzystująca grafową naturę kodu języków funkcyjnych do zrównoleglenia jego ewaluacji, opisana szczegółowo w [[cite:PeytonJones1992]].

Od wyboru architektury interpretera kodu bajtowego bardzo często zależą dostępne funkcjonalności docelowego języka programowania. W celu wybrania odpowiedniej architektury należy przeprowadzić szczegółową analizę porządanych funkcjonalności implementowanego języka i możliwości ich zrealizowania w poszczególnych modelach maszyny wirtualnej. Szczegółowa analiza wpływu języka na możliwość jego zaimplementowania w danej architekturze została zawarta w [[cite:Steele1978]] wraz z praktycznymi wskazówkami dotyczącymi implementacji maszyn wirtualnych, co okazało się niezastąpionym źródłem wiedzy pomocnym przy implementacji ThesisVM.

Interpreter kodu bajtowego zaimplementowany w ramach pracy wykorzystuje niskopoziomową architekturę stosową wykorzystującą wiele stosów oraz niewielki zbiór rejestrów i jest zmodyfikowaną wersją interpretera opisanego w $\cite[\text{rozdział 4}]{PeytonJones1992}$. Szczegółowy opis implementacji został zawarty w dedykowanej mu sekcji [[ref:sec:tvm-vm]] pracy.

** Zarządzanie pamięcią
Ważnym aspektem architektury maszyny wirtualnej jest sposób w jaki wykorzystuje ona pamięć operacyjną i rozdziela ją pomiędzy procesy w niej działające, czyli architektura wykorzystania sterty (ang. /heap architecture/).

Rysunek [[ref:fig:mem-archs]] przedstawia trzy główne architektury wykorzystania sterty w środowisku wielo-procesowym, gdzie wiele autonomicznych procesów konkuruje o zasób jakim jest pamięć:

- architektura *sterty prywatnej*, charakteryzująca się zupełną separacją pamięci poszczególnych procesów, co prowadzi do konieczności kopiowania obiektów składających się na wiadomości przesyłane pomiędzy nimi;

- architektura *sterty współdzielonej*, charakteryzująca się współdzieleniem jednego obszaru pamięci pomiędzy wszystkie procesy, dzięki czemu wiadomości (a także ich części) mogą być współdzielone przez procesy bez konieczności ich kopiowania;

- architektura *hybrydowa*, mająca za zadanie połączenie zalet obu powyższych rozwiązań przez separację danych lokalnych procesów i współdzielenie danych wiadomości przesyłanych pomiędzy procesami; rozwiązanie to wymaga skomplikowanej, statycznej analizy kodu programów, która nie zawsze może być przeprowadzona.

#+begin_center
#+label: fig:mem-archs
#+caption: Różne modele wykorzystania pamięci maszyn wirtualnych.
#+attr_latex: scale=1.0
[[file:./img/mem.pdf]]
#+end_center

Szczegółowa analiza wydajności architektur przedstawionych na rysunku [[ref:fig:mem-archs]] w kontekście języka =Erlang=, do semantyki którego ThesisVM jest bardzo zbliżona, została zawarta w [[cite:Wilhelmsson2005]]. Na podstawie tej analizy zdecydowano się zastosować architekturę sterty współdzielonej, która minimalizuje problem kopiowania pamięci (/ergo/, spełnia nieformalny cel pracy sformułowany w sekcji [[ref:sec:thesis-motivation]]) oraz nie wymaga skomplikowanej statycznej analizy kodu programów. Implementacja pozostawia jednak możliwość późniejszej modyfikacji architektury wykorzystania sterty.

Z problemem architektury wykorzystania sterty ściśle związany jest problem wyboru algorytmu alokacji pamięci. W [[cite:Wilson1995]] zawarto obszerne zestawienie algorytmów alokacji pamięci, na podstawie, którego zdecydowano się wykorzystać alokatory kaskadowe, /cache/'ujące pamięć zwolnionych obiektów w celu optymalizacji alokacji. Implementacja zastosowanego alokatora została zawarta w sekcji [[ref:sec:tvm-gc]].

Ostatnim aspektem zarządzania pamięci maszyny wirtualnej jest kolekcja pamięci obiektow nieosiągalnych. Kolektory obiektów nieosiągalnych można podzielić na dwa typy, ze względu na dane, które analizują:

- kolektory *śledzące* (ang. /tracing-GC/), które okresowo trawersują zbiór obiektów bazowych (ang. /root-set/) celem oznaczenia wszystkich obiektów /osiągalnych/ w danej chwili w systemie;

- kolektory *zliczające* (ang. /reference-counting-GC/), które na bieżąco zliczają ilość aktywnych referencji do każdego obiektu i natychmiastowo usuwają obiekty, których licznik referencji osiąga zero, co oznacza, że dany obiekt jest /nieosiągalny/.

Kolektory różnych typów mają bardzo różne charakterystyki wydajnościowe w zależności od architektury wykorzystania sterty zastosowanej w maszynie wirtualnej. Kolektory śledzące przeważnie generują długie pauzy w architekturach współdzielonych, natomiast kolektory zliczające prezentują stały narzut obliczeniowy związany z ciągłą modifykacją liczników referencji. Oczywiście istnieją dobrze poznane metody optymalizacji obu typu algorytmów [[cite:Shahriyar2012,Bacon2004]], które zacierają wszelkie różnice w ich charakterystykach wydajnościowych.

W implementacji ThesisVM zdecydowano się wykorzystać mechanizm automatycznej kolekcji "śmieci", oparty o /leniwe zliczanie referencji/, na podstawie wnikliwej analizy zawartej w [[cite:Bacon2004]] oraz w związku z wykorzystaniem podobnych algorytmów kolekcji danych binarnych w standardowej implementacji języka =Erlang=. Rozwiązanie to zostało szczegółowo opisane w sekcji [[ref:sec:tvm-gc]], a implementacja umożliwia późniejsze jej rozszerzenie o dodatkowe optymalizacje.

** Przetwarzanie współbieżne
Systemy współbieżne często realizują model symetrycznego multiprocessingu (/SMP/), którego cechą szczególną jest istnienie wielu identycznych jednostek operacyjnych wykonujących jednakowe operacje na różnych zbiorach danych (=SMPn= na rysunku [[ref:fig:amp-vs-smp]]).

#+begin_center
#+label: fig:amp-vs-smp
#+caption: Różne modele przetwarzania współbieżnego.
#+attr_latex: scale=0.5
[[file:./img/ampvssmp.pdf]]
#+end_center

Alternatywnym rozwiązaniem jest model asymetrycznego multiprocessingu (/AMP/) (=AMPn= na rysunku [[ref:fig:amp-vs-smp]]), gdzie dla różnych typów zadań istnieją dedykowane, wyspecjalizowane jednostki operacyjne, takie jak wątki, lub procesy systemu operacyjnego.

Rozwiązania asymetryczne są interesujące ze względu na zupełnie nowe klasy algorytmów, których implementację umożliwiają (na przykład algorytm zarządzania pamięcią VCGC [[cite:Huelsbergen1998]] wykorzystujący trzy asymetryczne wątki), jednak charakteryzują się skomplikowaniem interakcji poszczególnych jednostek operacyjnych a niejednokrotnie także słabą skalowalnością całego rozwiązania.

# TODO Rewrite the preceeding sentence.

Model przetwarzania współbieżnego został już przybliżony przy okazji ogólnego opisu architektury ThesisVM na początku rozdziału. Wybrany został model SMP, który w kontekście maszyny wirtualnej ThesisVM polega na zrównolegleniu wielu interpreterów kodu bajtowego operujących na różnych kontekstach procesów (zbiorach rejestrów i danych znajdujących się na ich stosach) w celu osiągnięcia realnej współbieżności interpretowanego kodu.

Dodatkową zaletą modelu SMP jest jego kompatybilność z Modelem Aktorowym [[cite:Hewitt1973]], którego głównym założeniem jest istnienie autonomicznych aktorów, którzy reagując na zmiany otoczenia dążą do swoich celów porozumiewając się z innymi aktorami za pośrednictwem wysyłania wiadomości [[cite:Clinger1981]]. W modelu SMP zastosowanym w maszynie wirtualnej ThesisVM aktorami są poszczególne procesy, które porozumiewają się za pomocą asynchronicznych wiadomości przesyłanych poprzez nieblokujące kolejki FIFO (ang. /First In Last Out/).

Szczegółowy opis implementacji symetrycznego multiprocesora i realizacja Modelu Aktorowego za jego pomocą zostały zawarte w sekcji [[ref:sec:tvm-smp]].

* Interpreter kodu bajtowego
#+latex: \label{sec:tvm-vm}

Niniejsza sekcja opisuje implementację interpretera kodu bajtowego ThesisVM. Jak już wspomniano w poprzedniej sekcji, praca implementuje model /Three Instruction Machine/, opisany szczegółowo w [[cite:Fairbairn1987]]
 oraz [[cite:PeytonJones1992]], wprowadzając do niego szereg modyfikacji.

Three Instruction Machine (TIM) jest nieskomplikowanym modelem maszyny wirtualnej opartym o trzy rejestry, służące do manipulacji danych:

- *IP* - wskaźnik /kodu/ następnej instrukcji,

- *Stack* - stos /kontynuacji/ skłądających się z wskaźnika do kodu oczekującego na ewaluację oraz kontekstu, w którym należy ów kod ewaluować,

- *Env* - stos będący obecnym /kontekstem/ ewaluacji kodu, który jest analogiczny do leksykalnego zasięgu zmięnnych w kodzie źródłowym programu;

#+latex: \noindent
oraz trzy bazowe instrukcje przyjmujące od zera do jednego argumentu, które w zupełności wystarczą do implementacji leniwych, funkcyjnych języków programowania:

- *PUSH arg* - tworzy kontynuację argumentu, która umożliwia jej późniejszą ewaluację w odpowiednim kontekście, odkładając ją na stos =Stack=,

- *TAKE* - pobiera kontynuację ze stosu Stack i przenosi ją na stos =Env= rozszerzając obecny kontekst ewaluacji kodu i przygotowując środowisko ewaluacji danej funkcji,

- *ENTER arg* - inicjuje ewaluację kontynuacji wskazywanej przez argument instrukcji odpowiednio modyfikując wartość rejestrów =IP= i =Env=.

#+latex: \noindent
Dodatkowo, instrukcje TIM posiadają różne typy adresowania argumentów, które wpływają na sposób interpretacji argumentu instrukcji:

- *VAL* - argument jest traktowany jako konkretna wartość,

- *CODE* - argument jest traktowany jako wskaźnik do konkretnej wartości,

- *ARG* - argument jest traktowany jako indeks stosu =Env=,

Ewaluacja kodu bajtowego TIM przebiega w standardowy sposób. Instrukcje pobierane są z adresu wskazywanego przez wskaźnik następnej instrukcji =IP=, po czym są dekodowane i wykonywane. Dekodowanie instrukcji polega na pobraniu kodu instrukcji oraz sposobu odresowania argumentu. Ostatnią fazą jest ustalenie konkretnej wartości argumentu na podstawie wcześniej ustalonego adresowania.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Przykład kodu bajtowego Three Instruction Machine.}}
#+latex: \label{code:tim-example}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src python
        PUSH ARG 0  # func
        ENTER ARG 0 # func
  func: TAKE
        PUSH ARG 0  # arg
        ENTER ARG 1 # func
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Na listingu [[ref:code:tim-example]] zawarto przykład kodu bajtowego definicji funkcji =func=, która przyjmuje jeden argument =arg= oraz wywołuje samą siebie z tym argumentem. Przed definicją funkcji (dwie instrukcji przed etykietą =func:=) zawarto także przykładowe wywołanie tej funkcji.

Warto zauważyć, że argumenty przekazywane do funkcji w modelu TIM są ewaluowane /leniwie/ - w przykładzie widniejącym na listingu [[ref:code:tim-example]] widać, że argument =arg= nigdy nie jest ewaluowany, nawet pomimo faktu, że funkcja =func= przekazuje go do następnego wywołania. Argumenty są ewaluowane dopiero w momencie, gdy maszyna potrzebuje ich konkretnej wartości.

Drugim ważnym spostrzeżeniem jest wsparcie /optymalizacji rekursji ogonowej/ modelu TIM - jeśli ostatnią instrukcją kodu ciała funkcji jest wywołanie innej funkcji, to wynikowy kod bajtowy zakończony będzie instrukcją ENTER, która nie wymaga zapisywania adresu powrotnego i tym samym gwarantuje stałą wielkość stosu programu.

Model Three Instruction Machine został wybrany jako podstawa implementacji ThesisVM ze względu na swoją prostotę i niewątpliwe zalety jakie posiada w kontekście implementacji funkcyjnych języków programowania. Istnieje wiele alternatywnych modeli działania maszyn wirtualnych, jak na przykład model /SECD/ [[cite:VanHorn2010]] oraz jego rekursywny ogonowo wariant /TR-SECD/ [[cite:Ramsdell1999]], czy bardziej adekwatne dla języków z rodziny Lisp modele opisane w [[cite:Abelson1996]] oraz [[cite:Steele1978]].

** Modyfikacje i implementacja modelu TIM
Zaprezentowany powyżej model jest bardzo prosty i pomimo swojej niewątpliwej ekspresywności, maszyna wirtualna go implementująca nie byłaby w stanie uruchamiać programów o praktycznym zastosowaniu. W związku z tym, model został rozszerzony o dodatkowy rejestr wskazujący na stos danych "prostych", nie będących kontynuacjami, a takżge szereg instrukcji implementujących podstawowe instrukcje arytmetyczne, logiczne i związane z implementacją Modelu Aktorowego.

#+begin_center
#+label: fig:tvm-regs
#+caption: Schemat stanu maszyny wirtualnej.
#+attr_latex: scale=1.5
[[file:./img/uProc.pdf]]
#+end_center

Na rysunku [[ref:fig:tvm-regs]] widnieje schemat rejestrów wykorzystywanych przez interpreter kodu bajtowego. Wymienione rejestry wraz z pozostałymi, opisanymi w następnych sekcjach pracy, składają się na kontekst mikroprocesów ThesisVM.

Rejestr *Header* zawiera informacje o typie procesu oraz metadane kolektora obiektów nieosiągalnych. Konteksty mikroprocesów maszyny ThesisVM są dostępne z poziomu kodu źródłowego, ponieważ są obiektami pierwszej klasy (ang. /first-class object/). Więcej informacji na temat zastosowania tego rejestru zostało zawarte w sekcji [[ref:sec:compound-objects]] opisującej implementację obiektów złożonych ThesisVM.

Rejestr *IP* służy do przechowywania wskaźnika następnej instrukcji kodu bajtowego. Jest wykorzystywany w dokładnie taki sam sposób, jak analogiczny rejestr modelu TIM. Rejestry *Env* oraz *Stack* podobnie jak rejestr =IP= również wykorzystywane są zgodnie z opisem modelu TIM.

Ostatni rejestr, *VStack* wskazuje na stos przechowujący dane "proste", czyli obiekty, które nie wymagają ewaluacji przez interpreter i mogą być wykorzystywane przez operacje prymitywne. Funkcjonalność tego stosu nie mogła zostać połączona z funkcjonalnością stosu =Stack=, ponieważ część instrukcji polega na homogeniczności danych znajdujących się na stosie =Stack= - jeśli istnienie na tym stosie danych innych niż kontynuacje zostałoby dozwolone, to część instrukcji wymagałaby kosztownego przeszukiwania i modyfikacji stosu.

Implementacja ThesisVM modyfikuje semantykę trzech bazowych instrukcji TIM:

- *NEXT addr arg* - jest to bardziej adekwatnie nazwany analog instrukcji =PUSH= podstawowego modelu TIM, w zależności od typu adresowania argument instrukcja ta tworzy i umieszcza na stosie =Stack= samo-ewaluującą do wartości argumentu kontynuację (=addr= równe =VAL=), kontynuację składającą się z obecnego kontekstu i wartości wskazywanej przez argument (=addr= równe =CODE=) lub wartść kontynuacji znajdującej się na stosie =Env= (wartość =addr= równa =ARG=);

- *TAKE* - podobnie jak w przypadku modelu bazowego, pobiera jedną kontynuację ze stosu kontynuacji =Stack= i umieszcza ją w obecnym kontekście ewaluacji =Env=;

- *ENTER addr arg* - w zależności od typu adresacji argumentu odpowiednio modyfikuje wartości rejestrów =Env= oraz =IP= podstawiając wartość =IP= na wartość argumentu (=addr= równe =CODE=), lub ewaluując kontynuację znajdującą się na stosie =Env= (wartość =addr= równa =ARG=);

#+latex: \noindent
oraz wprowadza kilka nowych instrukcji służących do obsługi dodatkowego rejestru i operacji prymitywnych z nim związanych:

- *PUSH arg* - jest to prosta instrukcja, której jedynym zadaniem jest umieszczenie argumentu na stosie =VStack=;

- *PRIMOP arg* - wykonuje operację prymitywną o identyfikatorze równym wartości argumentu. Więcej informacji o implementacji operacji prymitywnych zawarto w sekcji [[ref:sec:tvm-primops-impl]];

- *COND arg* - jest to instrukcja warunkowa, która sprawdza wartość znajdującą się na wierzchu stosu =VStack= i w zależności od jej wartości wybiera jedną z dwóch gałęzi kodu wskazywanych przez argument i ustawia jej wartość jako nową wartość rejestru =IP=;

- *SPAWN arg* - jest to instrukcja związana z implementacją Modelu Aktorowego, tworzy ona nowy kontekst mikroprocesu ThesisVM i aranżuje ewaluację kontynuacji znajdującej się na stosie =Env= pod indeksem równym wartości argumentu instrukcji (=arg=) przekazując jej jako parametr wartość znajdującą się na szczycie stosu =VStack=. Tak zaaranżowany kontekst mikroprocesu jest następnie dodawany do kolejki uruchomieniowej jednego z symetrycznych multiprocesorów wybranego zgodnie z zasadami równoważenia obciążenia (opisanymi w sekcji [[ref:sec:tvm-scheduling]]);

- *HALT* - instrukcja ta usypia proces na czas nieokreślony efektywnie kończąc jego działanie. Tak zatrzymany proces następnie podlega kolekcji przez kolektor obiektów nieosiągalnych, ponieważ mogą istnieć referencje nań wskazujące, które są wykorzystywane przez inne procesy.

** Implementacja obiektów prostych
Dane programów w maszynie ThesisVM reprezentowane są za pomocą dwóch rodzajów obiektów - obiektów "prostych" oraz obiektów złożonych. Rysunek [[ref:fig:tvmvalue-impl]] zawiera schemat reprezentacji obiektów prostych, które należą do jednego z trzech wspieranych typów podstawowych: =POINTER=, =FLOATING= lub =INTEGER=.

#+begin_center
#+label: fig:tvmvalue-impl
#+caption: Schemat reprezentacji obiektów prostych ThesisVM.
#+attr_latex: scale=0.8
[[file:./img/tvmvalue.pdf]]
#+end_center

Implementacja przechowuje dane obiektów prostych w strukturze o wielkości jednego słowa procesora (*64* bity w obecnej implementacji maszyny wirtualej przystosowanej do architektury *x86_64*), która zapewnia dostęp do dwóch pól identyfikujących odpowiednio 61-bitową wartość przechowywaną w strukturze oraz 3-bitowy typ, do którego owa wartość należy.

Wartość przechowywane są wraz z informacją o ich typie, w celu umożliwienia implementacji języków dynamicznie typowanych oraz ułatwienia pracy kolektora obiektów nieosiągalnych - dzięki informacji o typie może on precyzyjnie określić, czy dany obiekt jest referencją, czy też nie.

Typy obiektow prostych przechowywane są w trzech najmniej znaczących bitach (ang. /least significant bits/, /LSB/) reprezentacji, umożliwiając implementację ośmiu różnych typów podstawowych, zgodnie ze szczegółowym opisem zawartym w [[cite:Gudeman1993]]. Reprezentacja taka posiada szereg zalet począwszy od kompaktowości, przez brak konieczności alokacji pamięci dla typów podstawowych, kończąc na wielu ciekawych optymalizacjach, które umożliwia.

Na przykład, jeśli alokator maszyny wirtualnej wymusi /wyrównywanie pamięci/ (ang. /alignment/) do wielkości słowa procesora, to trzy najmniej znaczące bity (na architekturze 64-bitowej) reprezentacji wskaźników zawsze będą zerowe. W związku z tym, zerem można reprezentować typ wskaźnikowy obiektow prostych ThesisVM (typ =POINTER=), co umożliwia wykorzystywanie ich reprezentacji bezpośrednio, bez konieczności przeprowadzenia operacji bitowego maskowania.

Podobne optymalizacje mogą zostać zastosowane w przypadku reprezentacji obiektów numerycznych. Na przykład, w celu dodania dwóch liczb całkowitych (o typie =INTEGER=) można posłużyć się ostatnią zależnością zaprezentowaną na listingu [[ref:code:integer-optimization]] zamiast wielokrotnie wykorzystywać kosztowne operacje =tag= i =untag=, które realizują przejścia pomiędzy reprezentacją wewnętrzną obiektów maszyny wirtualnej a reprezentacją języka jej implementacji.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Optymalizacja dodawania liczb całkowitych.}}
#+latex: \label{code:integer-optimization}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src d
result = tag(Types.Integer, (untag(a) + untag(b)));
result = a.rawValue + b.rawValue - Types.INTEGER;
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Wiele ciekawych optymalizacji związanych ze sposobem reprezentacji typów obiektów zostało zawarte w [[cite:Gudeman1993]].

** Implementacja obiektów złożonych
#+latex: \label{sec:compound-objects}

#+begin_center
#+label: fig:tvmobject-impl
#+caption: Schemat reprezentacji obiektów złożonych ThesisVM.
#+attr_latex: scale=0.8
[[file:./img/tvmobject.pdf]]
#+end_center

- Opisać implementację obiektów złożonych ($\geq$ 8 bajtów - pary, funkcje/domknięcia, procesy).
- Opisać metodę tagowania (dolny bajt + reszta zarezerwowana dla GC). [[cite:Gudeman1993]], [[cite:Cook2013]]

- Opisać komponenty par.

- Opisać poszczególne komponenty obiektów funkcyjnych.

- Opisać reprezentację obiektów procesów (gołe rejestry).
- Opisać relację pomiędzy zbiorem rejestrów a reprezentacją procesu.

** Implementacja instrukcji kodu bajtowego
- Opisać reprezentację kodu bajtowego (listy opkodów).
- Opisać dostępne opkody kodu bajtowego. [[cite:Fairbairn1987,PeytonJones1992]]
- Opisać możliwe optymalizacje (wykorzystanie górnych dwóch bajtów słowa, 0 = pushc, threading, itd).

** Implementacja operacji prymitywnych
#+latex: \label{sec:tvm-primops-impl}

- Opisać wykorzystanie VStack.
- Opisać dostępne operacje prymitywne (LispKit). [[cite:Abelson1996]]
- Skonfrontować dostępne operacje prymitywne z =Core Erlang=. [[cite:Carlsson2004]]
- Opisać możliwe optymalizacje operacji arytmetycznych. [[cite:Gudeman1993]]

** Ewaluacja argumentów i aplikacja funkcji
- Opisać implementację stosów.
- Opisać dekodowanie instrukcji.
- Opisać działanie interpretera kodu bajtowego ThesisVM. [[cite:Fairbairn1987,PeytonJones1992]]
- Opisać aplikację operacji prymitywnych.
- Opisać brak apdejtowania już obliczonych wartości i dać link do sec:future-development.
- Opisać możliwość zastosowania bytecode threading.

** Generacja kodu bajtowego ThesisVM
#+latex: \label{sec:tvm-codegen}

- Zrobić listingi 
- Opisać szczegółowo generację kodu bajtowego. [[cite:PeytonJones1992]]

* Model zarządzania pamięcią
#+latex: \label{sec:tvm-gc}

- Opisać krótko architekturę wspólnej sterty. [[cite:Wilhelmsson2005]]

#+begin_center
#+label: ref:tvm-shared-mem
#+caption: Model wspólnej pamięci ThesisVM.
#+attr_latex: scale=1.5
[[file:./img/sharedmem.pdf]]
#+end_center

- Opisać strategie zarządzania pamięcią (alokator i GC). [[cite:Bacon2004]]

** Architektura wspólnej sterty
- Opisać szczegółowo wybraną architekturę.
- Wspomnieć o problemach wybranej architektury (duży root-set, długie kolekcje). [[cite:Wilhelmsson2005]]
- Skonfrontować publiczną stertę z architekturą prywatnej sterty. [[cite:Wilhelmsson2005]]
- Wspomnieć o problemach prywatnej sterty (powolne przekazywanie wiadomości przez kopiowanie). cite:Wilhelmsson2005
- Wspomnieć o istnieniu rozwiązań hybrydowych. [[cite:Wilhelmsson2005]]
- Wspomnięć o problemach rozwiązań hybrydowych (usunięte z =Erlang/OTP= R15B02).

** Implementacja alokatora obiektów
- Opisać działanie kaskadowego alokatora. [[cite:Wilson1995]]

#+begin_center
#+label: ref:tvm-alloc
#+caption: Schemat kaskadowych alokatorów wykorzystanych w ThesisVM.
#+attr_latex: scale=0.8
[[file:./img/allocator.pdf]]
#+end_center

- Opisać implementację wykorzystanego alokatora.
- Opisać optymalizacje alokatora (wykorzystanie free listy).
- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).
- Opisać krótko alternatywne rozwiązania (mallocator, etc). [[cite:Wilson1995]]

** Kolekcja nieosiągalnych obiektów
- Opisać leniwe zliczanie referencji. [[cite:Boehm2004]]

#+begin_center
#+label: ref:tvm-lazy-refcount-free
#+caption: Schemat działania zwalniania pamięci obiektów.
#+attr_latex: scale=0.8
[[file:./img/lazyrefcountfree.pdf]]
#+end_center

#+begin_center
#+label: ref:tvm-lazy-refcount-alloc
#+caption: Schemat działania alokacji pamięci nowych obiektów.
#+attr_latex: scale=0.8
[[file:./img/lazyrefcountalloc.pdf]]
#+end_center

- Opisać implementację algorytmu leniwego zliczania referencji. [[cite:Bacon2004]]
- Opisać konieczność wykorzystania operacji atomowych i barier pamięci (liczniki referencji).

#+begin_center
#+label: ref:tvm-gc-regs
#+caption: Schemat rejestrów wymaganych przez implementację kolektora obiektów nieosiągalnych.
#+attr_latex: scale=1.5
[[file:./img/GC.pdf]]
#+end_center

- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).
- Opisać narzut pamięci związany z licznikiem referencji i leniwością algorytmu. cite:Boehm2004,Bacon2004
- Opisać krótko wady, możliwe usprawnienia i alternatywne rozwiązania (zaproponowane przez Joe'go oraz VCGC) [[cite:Armstrong1995,Huelsbergen1998]]

** Kolekcja obiektów cyklicznych
- Opisać, że obiekty cykliczne nie występują.
- Wspomnieć o możliwości zaimplementowania zapasowego stop-the-world GC.
- Wspomnieć o możliwości cyklicznego uruchamiania D'owego GC.

* Model przetwarzania współbieżnego
#+latex: \label{sec:tvm-smp}

- Opisać bardziej szczegółowo Model Aktorowy i asynchroniczne przekazywanie wiadomości. [[cite:Hewitt1973,Clinger1981]]

#+begin_center
#+label: ref:tvm-smp
#+caption: Schemat symetrycznego multiprocesora ThesisVM.
#+attr_latex: scale=1.0
[[file:./img/SMP.pdf]]
#+end_center

- Opisać bardziej szczegółowo działanie SMP - wiadomości kontrolne oraz RQue.

** Implementacja Modelu Aktorowego
- Opisać powstawanie procesów i prymityw =spawn=.
- Opisać logiczną autonomiczność procesów (brak mutacji = inne procesy nie mogą ingerować).
- Opisać sposób porozumiewania się procesów (kolejki nieblokujące). [[cite:MichaelScott1996,Herlihy2002]]
- Opisać implementację kolejek nieblokujących (+ weryfikacja poprawności). [[cite:MichaelScott1996,Groves2008]]- Opisać wykorzystanie CAS i problem ABA.

#+begin_center
#+label: ref:tvm-actor-regs
#+caption: Schemat rejestrów wymaganych przez implementację Modelu Aktorowego.
#+attr_latex: scale=1.5
[[file:./img/Actor.pdf]]
#+end_center

- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).
- Opisać krótko wady i możliwe usprawnienia zastosowanego rozwiązania (dynamic size, wait-free, optimistic FIFO). [[cite:Herlihy2002,Kogan2011,Ladan-Mozes2004]]
- Opisać krótko alternatywne podejścia (synchroniczne przekazywanie wiadomości - kanały, locki/mutexy/semafory).

** Implementacja przesyłania wiadomości
- Opisać implementację prymitywów =send= oraz =receive=.
- Zwrócić uwagę na konieczność wykorzystania operacji atomowych oraz barier pamięci.
- Snippet kodu przesyłającego wiadomość.

#+begin_center
#+label: ref:tvm-msgs
#+caption: Schemat działania przesyłania wiadomości.
#+attr_latex: scale=1.2
[[file:./img/messagepassing.pdf]]
#+end_center

- Opisać co dzieje się podczas wysyłania wiadomości.
- Opisać sposób pobierania wiadomości z kolejki.
- Zwrócić uwagę na fakt, że problem kopiowania został zniwelowany kosztem lekkich barier pamięci.

** Harmonogramowanie procesów
#+latex: \label{sec:tvm-scheduling}

- Opisać sposób harmonogramowania procesów (brak load-balancingu, losowy spawn). [[cite:Pabla2009]]
- Opisać implementację prymitywu =sleep= oraz sleep-table.
- Opisać wiadomości kontrolne.

#+begin_center
#+label: ref:tvm-scheduler-regs
#+caption: Schemat rejestrów wymaganych przez usprawnienia hanmonogramowania SMP.
#+attr_latex: scale=1.5
[[file:./img/Scheduler.pdf]]
#+end_center

- Opisać możliwe usprawnienia (load-balancing i dzielenie zużycia).

* Podsumowanie
#+latex: \label{sec:conclusion}

- Opisać co udało się zrobić.
- Opisać czego nie udało się zrobić (+ możliwe usprawnienia).

** Interpreter kodu bajtowego
- Opisać dlaczego TIM się nie nadaje i trzeba to wymienić na coś innego.

** Kolektor obiektów nieosiągalnych
- Przeanalizować szybkość, pauzy, zużycie pamięci.

** Przetwarzanie współbieżne
- Przeanalizować szybkość przesyłania wiadomości/konieczność czekania procesów, wielkość kolejek wiadomości.

** Kierunki przyszłego rozwoju
#+latex: \label{sec:future-development}

- Opisać plany na przyszły rozwój projektu (priorytet procesów, load balancing SMP, wsparcie dla =Core Erlang=, bytecode threading, przebiegi optymalizacyjne podczas kompilacji, umożliwienie dystrybucji na wiele maszyn, zapasowy kolektor śmieci cyklicznych, opcja wykorzystania sterty prywatnej i autonomicznego alokatora, natywna kompilacja JIT, wektory, data-level parallelism, optymalizacja wykorzystania stosu, hardłerowa implementacja interpretera kodu bajtowego).

# The bibliography
#+begin_latex
\bibliographystyle{ieeetr}
\bibliography{bibs}
#+end_latex

#+latex: \appendix
* Przykładowe programy
#+latex: \label{sec:tvm-samples}

** Interfejs i użytkowanie ThesisVM
- Opisać sposób uruchamiania maszyny wirtualnej.

** "Hello world!"
** Funkcje i operacje prymitywne
** Factorial
** Fibonacci
** Współbieżne "Hello world!"
** Współbieżne obliczanie silni

* Spisy wbudowanych funkcji i operatorów
#+latex: \label{sec:tvm-primops}

#+begin_latex
{\Large\noindent\textbf{Spis funkcji wbudowanych}}
#+end_latex

- Wylistować funkcje wbudowane.

#+begin_latex
\vspace{2cm}
{\Large\noindent\textbf{Spis operatorów wbudowanych}}
#+end_latex

- Wylistować operacje prymitywne.

* Spisy rysunków, fragmentów kodu i tablic
#+latex: \label{sec:misc}

#+begin_latex
\begingroup
  \renewcommand*{\addvspace}[1]{}
  \listoffigures
  \listofmylisting
  \listoftables
\endgroup
#+end_latex

