################################################################################
#+TITLE: ThesisVM BEng
#+AUTHOR: Kajetan Rzepecki
#+DATE: 2013
#
#+BEGIN_OPTIONS
#+BIND: org-export-latex-title-command ""
#+STARTUP: content
#+LaTeX_CLASS: aghdpl
#+LaTeX_CLASS_OPTIONS: [a4paper, 12pt]
#+LaTeX_HEADER: \usepackage[polish]{babel}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{multicol}
#+LATEX_HEADER: \usepackage[nottoc, notlof, notlot]{tocbibind}
#+OPTIONS: tags:nil, todo:nil, toc:nil, date:nil
#+END_OPTIONS
####################

# Helpers & Stuff
#+begin_src emacs-lisp :exports none
  (add-to-list 'org-export-latex-classes
               '("aghdpl"
                 "\\documentclass{aghdpl}"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")
                 ))
  (setq org-export-latex-classes (cdr org-export-latex-classes))
#+end_src

# AGH setup:
#+BEGIN_OPTIONS
#+LATEX_HEADER: \shortauthor{K. Rzepecki}
#+LATEX_HEADER: \degreeprogramme{Informatyka}

#+LATEX_HEADER: \thesistype{Praca dyplomowa inżynierska}

#+LATEX_HEADER: \titlePL{Implementacja maszyny wirtualnej dla funkcyjnych języków programowania wspierających przetwarzanie współbieżne.}
#+LATEX_HEADER: \titleEN{Implementation of a virtual machine for functional programming languages with support for concurrent computing.}

#+LATEX_HEADER: \shorttitlePL{Implementacja maszyny wirtualnej dla funkcyjnych języków programowania \dots}
#+LATEX_HEADER: \shorttitleEN{Implementation of a virtual machine for functional programming languages \dots}

#+LATEX_HEADER: \supervisor{dr inż. Piotr Matyasik}

#+LATEX_HEADER: \department{Katedra Informatyki Stosowanej}

#+LATEX_HEADER: \faculty{Wydział Elektrotechniki, Automatyki,\protect\\[-1mm] Informatyki i Inżynierii Biomedycznej}

#+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję opiekunowi pracy za wsparcie merytoryczne oraz dobre rady edytorskie pomocne w tworzeniu pracy.}
#+END_OPTIONS

# Title pages & table of contents:
#+begin_latex
\titlepages
\tableofcontents
#+end_latex

# List of Listings specific:
#+begin_latex
\newcommand{\listlistingname}{\bfseries\Large{Spis listingów}}
\newlistof[chapter]{mylisting}{mlol}{\listlistingname}
\newcommand{\mylisting}[1]{%
  \refstepcounter{mylisting}%
  #1%
  \addcontentsline{mlol}{figure}
    {\protect\numberline{\thechapter.\thelisting}#1}\par%
}
\renewcommand{\cftbeforemloltitleskip}{20mm}
\renewcommand{\cftaftermloltitleskip}{5mm}
#+end_latex

* Wstęp
#+latex: \label{sec:intro}

Tematem pracy jest implementacja /maszyny wirtualnej/ dla funkcyjnych języków programowania wspierających /przetwarzanie współbieżne/.

Maszyna wirtualna jest warstwą abstrakcji leżącą pomiędzy programem a rzeczywistym sprzętem, która pozwala uniezależnić ów program od rozbieżności w działaniu różnych architektur komputerów. Wystarczy zaimplementować maszynę wirtualną dla danej architektury rzeczywistego sprzętu by umożliwić uruchamianie na niej wszystkich kompatybilnych z programów. Rysunek [[ref:fig:vm-arch]] prezentuje uproszczony schemat takiego rozwiązania - programy docelowe zostają skompilowane do /kodu bajtowego/ akceptowanego przez maszynę wirtualną a dopiero ów bajtkod jest przez nią uruchamiany.

#+begin_center
#+label: fig:vm-arch
#+caption: Schemat interakcji z Maszyną Wirtualną.
#+attr_latex: scale=0.7
[[file:./img/fullarch.pdf]]
#+end_center

Przetwarzanie współbieżne opiera się o współistnienie wielu procesów, które konkurują o dostęp do współdzielonych zasobów. W kontekście pracy, przetwarzanie współbieżne jest rozumiane jako asynchroniczne przekazywanie wiadomości pomiędzy działającymi, autonomicznymi procesami, czyli jako Model Aktorowy [[cite:Hewitt1973,Clinger1981]].

Celem pracy jest stworzenie interpretera kodu bajtowego zdolnego uruchamiać kod skompilowanych programów, kolektora obiektów nieosiągalnych umożliwiającego automatyczne zarządzanie pamięcią oraz architektury symetrycznego multiprocesora (SMP) zapewniającego rzeczywistą współbieżność uruchamianych programów w oparciu o Model Aktorowy.
Językiem implementacji projektu jest język =D= (w wersji 2.0 opisanej w [[cite:Alexandrescu2010]]), stosunkowo nowoczesny, kompilowany do kodu maszynowego następca języka =C++=.

** Motywacja pracy
#+latex: \label{sec:thesis-motivation}

Motywacją powstania pracy są problemy napotkane podczas użytkowania języka =Erlang= [[cite:Armstrong1996]], dotyczące wydajności przesyłania wiadomości średniego rozmiaru w obecnej, standardowej jego implementacji. Problemy owe zilustrowano na listingu [[ref:code:erlang-problem]].

Zaprezentowany fragment kodu odczytuje plik w formacie JSON, który następnie jest dekodowany do wewnętrznej reprezentacji posiadającej skomplikowaną strukturę, by ostatecznie został on wysłany do dużej liczby współbieżnie działających procesów celem dalszego przetwarzania (linia [[ref:line:bad]]). Rozwiązanie takie powoduje znaczący spadek wydajności.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Fragment kodu prezentujący problem występujący w języku \texttt{Erlang}.}}
#+latex: \label{code:erlang-problem}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src erlang
  start() ->
      Data = file:read("file.json"),    %% <<"Dane ...">>
      transmogrify(Data).
  
  transmogrify(Data) ->
      Pids = framework:spawn_bajilion_procs(fun do_stuff/1),
      JSON = json:decode(Data),         %% {[Dane ...]}
      framework:map_reduce(Pids, JSON). %% !#&^@ $\label{line:bad}$
  
  do_stuff(JSON) ->
      %% Operacje na danych.
      result.
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Język =Erlang= wykorzystuje skomplikowaną architekturę pamięci, która w różny sposób traktuje obiekty różnego typu. Większość obiektów, w szczególności skomplikowana strukturalnie reprezentacja danych w formacie JSON, przechowywana jest w prywatnych stertach każdego procesu i musi być kopiowana podczas przesyłania jej w wiadomościach pomiędzy nimi. Reguła ta nie dotyczy danych binarnych, w szczególności danych odczytanych z pliku, ponieważ te korzystają z innych algorytmów nie wymagających kopiowania kosztem większego zużycia pamięci.

W związku z tym, aby zaradzić problemowi opisanemu powyżej, wystarczy przenieść operację dekodowania danych odczytanych z pliku bezpośrednio do procesów na nich operujących (listing [[ref:code:erlang-solution]]).
W nowej wersji procesy przesyłają jedynie dane binarne, które nie wymagają kopiowania pamięci, a narzut wydajności spowodowany wielokrotnym ich dekodowaniem jest niższy niż ten spowodowany nadmiernym kopiowianiem. W efekcie, kod działa wydajniej, kosztem logiki przepływu danych i organizacji modułów.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Suboptymalne rozwiązanie problemu w języku \texttt{Erlang}.}}
#+latex: \label{code:erlang-solution}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true"))
#+begin_src erlang
  transmogrify(Data) ->
      Pids = framework:spawn_bajilion_procs(fun do_stuff/1),
      framework:map_reduce(Pids, Data).
  
  do_stuff(Data) ->             %% <<"Dane ...">>
      JSON = json:decode(Data), %% {[Dane ...]} * bazylion
      %% Operacje na danych.
      result.
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Celem pracy jest uniknięcie problemu nadmiernego kopiowania pamięci przez wybranie odpowiedniego modelu pamięci i implementację algorytmów kolekcji obiektow nieosiągalnych, które umożliwiają przesyłanie wiadomości pomiędzy procesami bez konieczności kopiowania ich zawartości.

** Zawartość pracy
W skład pracy wchodzi implementacja interpretera kodu bajtowego, kolektora obiektów nieosiągalnych oraz symetrycznego multiprocesora (SMP).

Sekcja [[ref:sec:intro]] opisuje cele, motywację, zakres oraz zawartość pracy.

Sekcja [[ref:sec:tvm-arch]] przybliża architekturę maszyny wirtualnej ThesisVM zaimplementowanej w ramach pracy, zaczynając od reprezentacji pośredniej programów (TVMIR) i jej kompilacji do kodu bajtowego, przez interpretację kodu bajtowego i zarządzanie pamięcią do projektu przetwarzania współbieżnego.

Sekcja [[ref:sec:tvm-vm]] szczegółowo opisuje implementację interpretera kodu bajtowego maszyny wirtualnej ThesisVM. Zaprezentowane zostają reprezentacje różnych obiektów, na których operuje maszyna, implementacja wpudowanych operatorów i funkcji prymitywnych oraz reprezentacja i generowanie kodu bajtowego akceptowanego przez interpreter.

Sekcja [[ref:sec:tvm-gc]] szczegółowo prezentuje implementację wybranego modelu pamięci, alokatora nowych obiektów oraz kolektora obiektów nieosiągalnych.

Sekcja [[ref:sec:tvm-smp]] szczegółowo opisuje implementację asynchronicznego przekazywania wiadomości i symetrycznego multiprocesora w maszynie ThesisVM. Zaprezentowana zostaje implementacja Modelu Aktorowego i harmonogramowania procesów.

Sekcja [[ref:sec:conclusion]] zawiera podsumowanie pracy oraz zarys możliwych kierunków dalszego rozwoju projektu.

Dodatki [[ref:sec:tvm-samples]], [[ref:sec:tvm-primops]] i [[ref:sec:misc]] zawierają odpowiednio przykładowe programy gotowe do uruchomienia na maszynie wirtualnej ThesisVM, spis wbudowanych operatorów i funkcji prymitywnych oraz spisy rysunków, tablic i fragmentów kodu znajdujących się w tekście pracy.

* Architektura ThesisVM
#+latex: \label{sec:tvm-arch}

Ninejsza sekcja opisuje architekturę maszyny wirtualnej ThesisVM powstałej na potrzeby pracy oraz języka przez nią akceptowanego.

Rysunek [[ref:fig:tvm-arch]] zawiera schematyczną reprezentację maszyny wirtualnej ThesisVM uwzględniającą architekturę procesora sprzętu, na którym działa system operacyjny oraz sama maszyna wirtualna. Na schemacie widać poszczególne podsystemy ThesisVM, takie jak autonomiczne procesy (zwane dalej /mikroprocesami/, =µProcN=), czy symetryczne multiprocesory (zwane dalej =SMPn=).

Mikroprocesy są przypisane do symetrycznych multiprocesorów w stosunku wiele-do-jednego, to znaczy każdy mikroproces jest przypisany do dokładnie jednego symetrycznego multiprocesora, który natomiast może zarządzać zbiorem wielu mikroprocesów.

#+begin_center
#+label: fig:tvm-arch
#+caption: Architektura maszyny wirtualnej ThesisVM.
#+attr_latex: scale=1.0
[[file:./img/arch.pdf]]
#+end_center

Każdy symetryczny multiprocesor działa w osobnym wątku procesora sprzętowego, zapewniając rzeczywistą współbieżność. Wszystkie =SMPn= są takie same i wykonują takie same zadania, czyli harmonogramowanie i wywłaszczanie mikroprocesów, a różni je jedynie stan, w którym się znajdują oraz zbiór procesów, którymi zarządzają.
Na schemacie widnieje mapowanie jeden-do-jednego pomiędzy rdzeniami procesora (=CPUn=) a poszczególnymi =SMPn=, nie jest to jednak wymóg konieczny i zależy od konfiguracji maszyny wirtualnej. Konfigurowalna ilość równocześnie działających SMP pomaga osiągnąć lepszą skalowalność maszyny wirtualnej i może być zmieniana dynamicznie wedle potrzeb.

Pozostając w zgodzie ze schematem przedstawionym na rysunku [[ref:fig:vm-arch]], interakcja z maszyną ThesisVM przebiega w analogiczny sposób. Kod programów w reprezentacji pośredniej (TVMIR) jest kompilowany do kodu bajtowego akceptowanego przez maszynę wirtualną, która następnie go ładuje i wykonuje umożliwiając zrównoleglenie obliczeń poprzez tworzenie nowych procesów i przesyłanie pomiędzy nimi wiadomości.

** Reprezentacja pośrednia programów
ThesisVM wykorzystuje prostą reprezentację pośrednią programów w postaci TVMIR - języka lisp'owego z rodziny =Scheme= [[cite:Abelson1996]], który jest dostatecznie ekspresywny, by można w nim było zapisać nietrywialne algorytmy, a jednocześnie na tyle prosty, by ułatwić jego późniejszą kompilację do kodu bajtowego akceptowanego przez maszynę wirtualną.

Języki pośrednie reprezentacji programów są często stosowane w implementacjach wielu maszyn wirtualnych, takich jak ParrotVM, czy CoreVM [[cite:PeytonJones1992]], a także w implementacjach kompilatorów kodu maszynowego wielu języków programowania (na przykład GCC, LLVM). Reprezentacje pośrednie mają wiele zalet, począwszy od ułatwienia wsparcia dla szerszej gamy języków wysokiego poziomu, na możliwości tworzenia wygodnych założeń dodatkowych kończąc.

Na listingu [[ref:code:tvmir]] spisana w formacie BNF została gramatyka języka reprezentacji pośredniej wykorzystanego w maszynie wirtualnej ThesisVM. Gramatyka ta jest nieskomplikowana i w dużej mierze przypomina gramatiki różnych dialektów języka =Lisp=.

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Gramatyka języka TVMIR.}}
#+latex: \label{code:tvmir}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))
#+begin_src xml
  <program>           ::= <definitions>
  <definitions>       ::= <definition> <definitions> | ''
  <definition>        ::= '(' 'define' <argument-list>
                                       <function-body> ')'
  <argument-list>     ::= '(' <function-name> <arguments> ')'
  <arguments>         ::= <argument-name> <arguments> | ''
  <argument-name>     ::= <symbol>
  <function-name>     ::= <symbol>
  <function-body>     ::= <expression>
  <expression>        ::= <simple-expression> | <application>
                        | <conditional> | <quote>
  <simple-expression> ::= <list> | <symbol> | <number>
  <application>       ::= '(' <expression> <expressions> ')'
  <expressions>       ::= <exrpession> <exrpessions> | ''
  <conditional>       ::= '(' 'if' <expression>
                                   <expression>
                                   <expression> ')'
  <quote>             ::= ''' <expression>
  <list>              ::= '(' <expression> ')'
  <symbol>            ::= <literal-string> | <atom>
  <literal-string>    ::= '"' "Dowolny literał znakowy." '"'
  <atom>              ::= "Dowolny literał znakowy bez znaków białych."
  <number>            ::= "Dowolny literał liczbowy."
#+end_src
#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Języki z rodziny =Lisp= są bardzo wygodnym medium dla pośredniej reprezentacji programów ponieważ przedstawiają one drzewo syntaktyczne analizowanego kodu programu i nie wymagają skomplikowanego algorytmu parsowania. Dodatkowo, homoikoniczność tych języków może pomóc w tworzeniu narzędzi służących do przetwarzania kodu rozpatrywanego języka (w szczególności kompilatorów) bezpośrednio w rozpatrywanym języku. Temat ten został dogłębnie zbadany w [[cite:Abelson1996]]. Dodatek [[ref:sec:tvm-samples]] zawiera przykłady kodu w języku pośredniej reprezentacji programów TVMIR.

Język reprezentacji pośredniej przedstawiony w pracy wymaga stworzenia kilku założeń dodatkowych dotyczących transformacji kodu. Najważniejszym z nich jest konieczność przeprowadzenia operacji lambda-unoszenia (ang. /lambda lifting/), opisanej bardzo dokładnie w [[cite:PeytonJones1992]], której efekt zaprezentowano na listingu [[ref:code:lambda-lifting]].

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Fragmenty kodu prezentujące operację lambda-unoszenia.}}
#+latex: \label{code:lambda-lifting}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))

#+latex: \begin{multicols}{2}
#+begin_src scheme
  ;; Przed lambda-unoszeniem:
  (define (make-adder n)
    (lambda (x)
      (+ x n)))
#+end_src

#+latex: \columnbreak
#+begin_src scheme
  ;; Po lambda-unoszeniu:
  (define (__make-adder_lambda0 n x)
    (+ x n))
  
  (define (make-adder n)
    (__make-adder_lambda n))
#+end_src
#+latex: \end{multicols}

#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Lambda-unoszenie polega na transformacji ciał funkcji w taki sposób, by tworzone w nich funkcje anonimowe zostały przeniesione na poziom główny zasięgu nazw (ang. /top-level scope/) dzięki czemu do ich implementacji wystarczy jedynie częściowa aplikacja funkcji. Na drugiej części listingu [[ref:code:lambda-lifting]] funkcja =make-adder= zwracająca anonimową funkcję została transformowana na dwie funkcje, z których =make-adder= pozostaje funkcją unarną, która korzysta z częściowej aplikacji funkcji binarnej =__make-adder_lambda0= wykonującej operację dodawania.

Pełna i poprawna implementacja operacji lambda-unoszenia jest skomplikowana, toteż nie została zawarta w dołączonym do projektu kompilatorze kodu bajtowego i musi zostać wykonana ręcznie.

Język pośredniej reprezentacji programów zastosowany w maszynie wirtualnej ThesisVM jest bardzo podobny do języka =Core Lang= wykorzystywanego w [[cite:PeytonJones1992]], jednak nie wspiera on niektórych jego konstrukcji, takich jak =let(rec)=, czy definicje dowolnych obiektów złożonych. Z drugiej strony wspiera on konstrukcje związane z Modelem Aktorowym (=receive=, =send= oraz =spawn=) oraz jest w stanie emulować brakujące konstrukcje odpowiednio przez wykorzystanie transformacji kodu połączonej z lambda-unoszeniem (listing [[ref:code:poor-mans-let]]) oraz "tagowania" list (przechowywania informacji o typie obiektu w pierwszym elemencie listy enkodującej ten obiekt).

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Ograniczona implementacja konstrukcji \texttt{let}.}}
#+latex: \label{code:poor-mans-let}
#+bind: org-export-latex-minted-options (("frame" "leftline") ("linenos" "true") ("mathescape" "true"))

#+latex: \begin{multicols}{2}
#+begin_src scheme
  ;; Przed transformacją:
  (define (function x)
    (let ((value (* 2 x)))
      (* value value)))

  ;; Po transformacji:
  (define (function x)
    ((lambda (value)
       (* value value))
     (* 2 x)))
#+end_src

#+latex: \columnbreak
#+begin_src scheme
  ;; Po lambda-unoszeniu:
  (define (__function_lambda0 value)
    (* value value))

  (define (function x)
    (__function_lambda0 (* 2 x)))
#+end_src
#+latex: \end{multicols}

#+bind: org-export-latex-minted-options ()
#+latex: \end{listing}

Kolejnym podobnym językiem reprezentacji pośredniej jest =Core Erlang= [[cite:Carlsson2001]] wykorzystywany w standardowej implementacji języka =Erlang=. TVMIR jest bardzo okrojoną wersją języka =Core Erlang=, pozbawioną elementów dopasowywania wzorców, która jednak wspiera pozostałe ważne jego elementy, takie jak konstrukcje odpowiedzialne za tworzenie procesów oraz przesyłanie i odbieranie wiadomości.
Istnieje możliwość rozszerzenia funkcjonalności TVMIR celem wsparcia pełnej specyfikacji =Core Erlang= [[cite:Carlsson2004]], jednak jest to poza zakresem pracy. Więcej informacji o przyszłych kierunkach rozwoju projektu zostało zawarte w sekcji [[ref:sec:future-development]].

** Kompilacja kodu bajtowego

Język pośredniej reprezentacji programów jest wygodnym medium do zapisu algorytmów, jednak wymaga on uprzedniego skompilowania do kodu bajtowego, który jest akceptowany przez maszynę wirtualną ThesisVM.

Ponieważ kompilacja kodu nie jest /stricte/ tematem pracy, mniej ważne szczegóły implementacji zostały pominięte, a niniejsza sekcja zarysowuje poszczególne fazy kompilacji kodu bajtowego ThesisVM.

Rysunek [[ref:fig:tvm-compiler-pipeline]] zawiera schemat działania kompilatora kodu bajtowego ThesisVM wraz z przykładami pośrednich reprezentacji kompilowanego kodu w poszczególnych fazach kompilacji.

#+begin_center
#+label: fig:tvm-compiler-pipeline
#+caption: Schemat potokowega działania kompilatora kodu bajtowego ThesisVM wraz ze przykładami reprezentacji danych poszczególnych faz kompilacji.
#+attr_latex: scale=0.5
[[file:./img/pipeline.pdf]]
#+end_center

Kompilator został zaimplementowany w sposób /potokowy/, to znaczy poszczególne fazy są logicznie odseparowane od siebie i wykonywane jedna po drugiej. Dzięki zastosowaniu leniwych konstrukcji języka =D= [[cite:Alexandrescu2010]] wszystkie te fazy odbywają się /jednocześnie/ i /na rządanie/ a w przypadku wykrycia błędu w danej fazie poprzednie fazy natychmiastowo się kończą, bez konieczności przetworzenia całego zestawu danych, które otrzymały na wejściu.

Pierwszą fazą jest faza analizy leksykalnej, której zadaniem jest przetworzenie /strumienia znaków/ kodu źródłowego programu w pośredniej reprezentacji TVMIR do /strumienia tokenów/, czyli elementarnych ciągów znaków będących leksemami języka. Faza ta przeprowadza także walidację składni na poziomie tokenów oraz filtrację niepotrzebnych tokenów (takich jak znaki białe, które nie mają znaczenia w TVMIR).

Drugą fazą jest faza analizy syntaktycznej, której zadaniem jest przetworzenie powstającego leniwie /strumienia tokenów/ na /wstępne drzewo parsowania/ składające się z prymitywnych konstrukcji języka TVMIR, takich jak listy, symbole i liczby. Faza ta waliduje składnię na poziomie zaawansowanych konstrukcji języka, które dzięki jego homoikoniczności zbudowane są z prymitywniejszych jego konstrukcji.

Trzecią fazą jest faza analizy semantycznej, której zadaniem jest przetworzenie /wstępnego drzewa parsowania/ na bardziej abstrakcyjne /drzewo składniowe/ składające się semantycznie znaczących węzłów, takich jak aplikacja funkcji, wywołania operatorów wbudowanych, czy odwołania do zmiennych. Faza ta waliduje kod na poziomie semantycznym, sprawdzając poprawność wykorzystania różnych konstrukcji języka TVMIR.

Czwartą fazą jest faza optymalizacji, której zadaniem jest transformacja /drzewa składniowego/ powstałego w poprzedniej fazie do jego ekwiwalentu działającego szybciej po skompilowaniu. Faza ta obecnie nie wykonuje rzadnych interesujących transformacji, jednak istnieje możliwość rozszerzenia jej funkcjonalności w przyszłości (opisane krótko w sekcji [[ref:sec:future-development]]).

Ostatnią, piątą fazą kompilacji jest faza generacji kodu bajtowego akceptowanego przez ThesisVM. Zadaniem tej fazy jest przetworzenie /drzewa składniowego/ do /strumienia kodu bajtowego/ za pomocą reguł kompilacji zgodnych z wybranym modelem maszyny wirtualnej (opisane szczegółowo w sekcji [[ref:sec:tvm-codegen]]).

** Interpretacja kodu bajtowego
Istnieje wiele różnych modeli maszyn wirtualnych cechujących się różnymi architekturami interpreterów kodu bajtowego, czy nawet stopniem abstrakcyjności (tak zwane maszyny abstrakcyjne).

Pod względem architektury interpretera kodu bajtowego można wyróżnić trzy główne architektury maszyn wirtualnych:

- architekturę *stosową*, korzystającą ekskluzywnie z jednego lub wielu stosów podczas przetwarzania danych, która charakteryzuje się krótkimi, pod względem zajmowanej pamięci, instrukcjami;

- architekturę *rejestrową*, korzystającą ekskluzywnie z wielu rejestrów podczas przetwarzania danych, która charakteryzuje się instrukcjami przyjmującymi wiele argumentów określających adresy rejestrów maszyny;

- architektury *hybrydowe*, łączące dwa powyższe rozwiązania w różnym stopniu.

Pod względem abstrakcyjności maszyny wirtualne można podzielić na dwie główne grupy:

- *niskopoziomowe*, do których należą maszyny implementujące wyżej wymienione architektury; główną cechą maszyn niskopoziomowych jest obecność stosunkowo nieskomplikowanego kodu bajtowego, który jest przez maszynę interpretowany podczas jej działania;

- *wysokopoziomowe*, które wymagają niestandardowego traktowania kodu programów; na przykład maszyna redukcji grafowych G-machine wykorzystująca grafową naturę kodu języków funkcyjnych do zrównoleglenia jego ewaluacji, opisana szczegółowo w [[cite:PeytonJones1992]].

Od wyboru architektury interpretera kodu bajtowego bardzo często zależą dostępne funkcjonalności docelowego języka programowania. W celu wybrania odpowiedniej architektury należy przeprowadzić szczegółową analizę porządanych funkcjonalności implementowanego języka i możliwości ich zrealizowania w poszczególnych modelach maszyny wirtualnej. Szczegółowa analiza wpływu języka na możliwość jego zaimplementowania w danej architekturze została zawarta w [[cite:Steele1978]] wraz z praktycznymi wskazówkami dotyczącymi implementacji maszyn wirtualnych, co okazało się niezastąpionym źródłem wiedzy pomocnym przy implementacji ThesisVM.

Interpreter kodu bajtowego zaimplementowany w ramach pracy wykorzystuje niskopoziomową architekturę stosową wykorzystującą wiele stosów oraz niewielki zbiór rejestrów i jest zmodyfikowaną wersją interpretera opisanego w $\cite[\text{rozdział 4}]{PeytonJones1992}$. Szczegółowy opis implementacji został zawarty w dedykowanej mu sekcji [[ref:sec:tvm-vm]] pracy.

** Zarządzanie pamięcią
Ważnym aspektem architektury maszyny wirtualnej jest sposób w jaki wykorzystuje ona pamięć operacyjną i rozdziela ją pomiędzy procesy w niej działające, czyli architektura wykorzystania sterty (ang. /heap architecture/).

Rysunek [[ref:fig:mem-archs]] przedstawia trzy główne architektury wykorzystania sterty w środowisku wielo-procesowym, gdzie wiele autonomicznych procesów konkuruje o zasób jakim jest pamięć:

- architektura *sterty prywatnej*, charakteryzująca się zupełną separacją pamięci poszczególnych procesów, co prowadzi do konieczności kopiowania obiektów składających się na wiadomości przesyłane pomiędzy nimi;

- architektura *sterty współdzielonej*, charakteryzująca się współdzieleniem jednego obszaru pamięci pomiędzy wszystkie procesy, dzięki czemu wiadomości (a także ich części) mogą być współdzielone przez procesy bez konieczności ich kopiowania;

- architektura *hybrydowa*, mająca za zadanie połączenie zalet obu powyższych rozwiązać przez separację danych lokalnych procesów i współdzielenie danych wiadomości przesyłanych pomiędzy procesami; rozwiązanie to wymaga skomplikowanej, statycznej analizy kodu programów, która nie zawsze może być przeprowadzone.

#+begin_center
#+label: fig:mem-archs
#+caption: Różne modele wykorzystania pamięci maszyn wirtualnych.
#+attr_latex: scale=1.0
[[file:./img/mem.pdf]]
#+end_center

Szczegółowa analiza wydajności architektur przedstawionych na rysunku [[ref:fig:mem-archs]] w kontekście języka =Erlang=, do semantyki którego ThesisVM jest bardzo zbliżona, została zawarta w [[cite:Wilhelmsson2005]]. Na podstawie tej analizy zdecydowano się zastosować architekturę sterty współdzielonej, która minimalizuje problem kopiowania pamięci (/ergo/, spełnia nieformalny cel pracy sformułowany w sekcji [[ref:sec:thesis-motivation]]) oraz nie wymaga skomplikowanej statycznej analizy kodu programów. Implementacja pozostawia jednak możliwość późniejszej modyfikacji architektury wykorzystania sterty.

Z problemem architektury wykorzystania sterty ściśle związany jest problem wyboru algorytmu alokacji pamięci. W [[cite:Wilson1995]] zawarto obszerne zestawienie algorytmów alokacji pamięci, na podstawie, którego zdecydowano się wykorzystać alokatory kaskadowe, /cache/'ujące pamięć zwolnionych obiektów w celu optymalizacji alokacji. Implementacja zastosowanego alokatora została zawarta w sekcji [[ref:sec:tvm-gc]].

Ostatnim aspektem zarządzania pamięci maszyny wirtualnej jest kolekcja pamięci obiektow nieosiągalnych. Kolektory obiektów nieosiągalnych można podzielić na dwa typy, ze względu na dane, które analizują:

- kolektory *śledzące* (ang. /tracing-GC/), które okresowo trawersują zbiór obiektów bazowych (ang. /root-set/) celem oznaczenia wszystkich obiektów /osiągalnych/ w danej chwili w systemie;

- kolektory *zliczające* (ang. /reference-counting-GC/), które na bieżąco zliczają ilość aktywnych referencji do każdego obiektu i natychmiastowo usuwają obiekty, których licznik referencji osiąga zero, co oznacza, że dany obiekt jest /nieosiągalny/.

Kolektory różnych typów mają bardzo różne charakterystyki wydajnościowe w zależności od architektury wykorzystania sterty zastosowanej w maszynie wirtualnej. Kolektory śledzące przeważnie generują długie pauzy w architekturach współdzielonych, natomiast kolektory zliczające prezentują stały narzut obliczeniowy związany z ciągłą modifykacją liczników referencji. Oczywiście istnieją dobrze poznane metody optymalizacji obu typu algorytmów [[cite:Shahriyar2012,Bacon2004]], które zacierają wszelkie różnice w ich charakterystykach wydajnościowych.

W implementacji ThesisVM zdecydowano się wykorzystać mechanizm automatycznej kolekcji "śmieci" oparty o /leniwe zliczanie referencji/, na podstawie wnikliwej analizy zawartej w [[cite:Bacon2004]] oraz w związku z wykorzystaniem podobnych algorytmów kolekcji danych binarnych w standardowej implementacji języka =Erlang=. Rozwiązanie to zostało szczegółowo opisane w sekcji [[ref:sec:tvm-gc]], a implementacja umożliwia późniejsze jej rozszerzenie o dodatkowe optymalizacje.

** Przetwarzanie współbieżne
Model przetwarzania współbieżnego został już przybliżony przy okazji ogólnego opisu architektury ThesisVM na początku rozdziału. Wybrany został model SMP - symetryczny multiprocesor, którego cechą szczególną jest istnienie wielu identycznych jednostek operacyjnych, wykonujących jednakowe operacje na różnych zbiorach danych.

Alternatywnym rozwiązaniem jest model asymetrycznego multiprocessingu, gdzie dla różnych typów zadań istnieją dedykowane jednostki operacyjne (na przykład dedykowane wątki aplikacji). Rozwiązania asymetryczne są interesujące ze względu na zupełnie nowe klasy algorytmów zarządzania pamięci, których implementację umożliwiają (na przykład algorytm VCGC [[cite:Huelsbergen1998]] wykorzystujący trzy asymetryczne wątki), jednak przeważnie ich skalowalność jest ograniczona w związku z czym ich wykorzystanie w implementacji ThesisVM jest niewskazane.

W kontekście maszyny wirtualnej ThesisVM model symetrycznego multiprocessingu polega na zrównolegleniu wielu interpreterów kodu bajtowego operujących na różnych kontekstach procesów (zbiorach rejestrów i danych znajdujących się na ich stosach) w celu osiągnięcia realnej współbieżności interpretowanego kodu. Dodatkową zaletą modelu SMP jest jego kompatybilność z Modelem Aktorowym współbieżności.

Głównymi założeniami Modelu Aktorowego [[cite:Hewitt1973]] jest istnienie autonomicznych aktorów, którzy reagując na zmiany otoczenia dążą do swoich celów porozumiewając się z innymi aktorami za pośrednictwem wysyłania wiadomości [[cite:Clinger1981]]. W modelu SMP zastosowanym w maszynie wirtualnej ThesisVM aktorami są poszczególne procesy, które porozumiewają się za pomocą asynchronicznych wiadomości przesyłanych poprzez nieblokujące kolejki FIFO, celem wykonania zaprogramowanych operacji.

Szczegółowy opis implementacji symetrycznego multiprocesora i realizacja Modelu Aktorowego za jego pomocą zostały zawarte w sekcji [[ref:sec:tvm-smp]].

* Interpreter kodu bajtowego
#+latex: \label{sec:tvm-vm}

- Opisać wybrany model Three Instruction Machine. [[cite:Fairbairn1987,PeytonJones1992]], [[cite:Kaser1992]]
- Opisać krótko działanie TIM, zwrócić uwagę na leniwość. [[cite:Fairbairn1987,PeytonJones1992]], [[cite:Kaser1992]]
- Opisać modyfikacje modelu TIM.

#+begin_center
#+label: ref:tvm-regs
#+caption: Schemat stanu maszyny wirtualnej.
#+attr_latex: scale=1.5
[[file:./img/uProc2.pdf]]
#+end_center

- Opisać wykorzystywane rejestry.
- Opisać krótko alternatywne rozwiązania (SECD, TRSECD, SICP machine). [[cite:VanHorn2010,Ramsdell1999,Abelson1996,Steele1978]], [[cite:Kaser1992]]

** Implementacja obietków prostych
- Opisać implementację atomów ($\leq$ 8 bajtów).
- Opisać metodę tagowania atomów (dolne trzy bity) [[cite:Gudeman1993]], [[cite:Cook2013]]
- Opisąć optymalizacje/trejdofy wybranego sposobu tagowania. [[cite:Gudeman1993]], [[cite:Cook2013]]

** Implementacja obiektów złożonych
- Opisać implementację obiektów złożonych ($\geq$ 8 bajtów - pary, funkcje/domknięcia, procesy).
- Opisać metodę tagowania (dolne dwa bajty + górne 48 bitów zarezerwowane dla GC). [[cite:Gudeman1993]], [[cite:Cook2013]]
- Opisać komponenty par.
- Opisać poszczególne komponenty obiektów funkcyjnych.
- Opisać reprezentację obiektów procesów (gołe rejestry).
- Opisać relację pomiędzy zbiorem rejestrów a reprezentacją procesu.

** Implementacja wbudowanych operatorów
- Opisać wykorzystanie VStack.
- Opisać dostępne operacje prymitywne (LispKit). [[cite:Abelson1996]]
- Skonfrontować dostępne operacje prymitywne z =Core Erlang=. [[cite:Carlsson2004]]
- Opisać optymalizacje operacji arytmetycznych. [[cite:Gudeman1993]]

** Ewaluacja argumentów i aplikacja funkcji
- Opisać działanie interpretera kodu bajtowego ThesisVM. [[cite:Fairbairn1987,PeytonJones1992]]
- Opisać leniwą ewaluację argumentów.
- Opisać aplikację funkcji.
- Opisać aplikację operacji prymitywnych.

** Reprezentacja kodu bajtowego ThesisVM
- Opisać reprezentację kodu bajtowego (listy opkodów).
- Opisać optymalizacje TVMBC (wykorzystanie górnych dwóch bajtów słowa, 0 = pushc, threading, itd).
- Opisać dostępne opkody kodu bajtowego. [[cite:Fairbairn1987,PeytonJones1992]]

** Generacja kodu bajtowego ThesisVM
#+latex: \label{sec:tvm-codegen}

- Opisać szczegółowo generację kodu bajtowego. [[cite:PeytonJones1992]]

* Model zarządzania pamięcią
#+latex: \label{sec:tvm-gc}

- Opisać krótko architekturę wspólnej sterty. [[cite:Wilhelmsson2005]]

# TODO Actually make this.
#+begin_center
#+label: ref:tvm-shared-mem
#+caption: Model wspólnej pamięci ThesisVM.
#+attr_latex: scale=1.2
[[file:./img/sharedmem.pdf]]
#+end_center

- Opisać strategie zarządzania pamięcią (alokator i GC). [[cite:Bacon2004]]

** Architektura wspólnej sterty
- Opisać szczegółowo wybraną architekturę.
- Wspomnieć o problemach wybranej architektury (duży root-set, długie kolekcje). [[cite:Wilhelmsson2005]]
- Skonfrontować publiczną stertę z architekturą prywatnej sterty. [[cite:Wilhelmsson2005]]
- Wspomnieć o problemach prywatnej sterty (powolne przekazywanie wiadomości przez kopiowanie). cite:Wilhelmsson2005
- Wspomnieć o istnieniu rozwiązań hybrydowych. [[cite:Wilhelmsson2005]]
- Wspomnięć o problemach rozwiązań hybrydowych (usunięte z =Erlang/OTP= R15B02).

** Implementacja alokatora obiektów
- Opisać działanie kaskadowego alokatora. [[cite:Wilson1995]]

#+begin_center
#+label: ref:tvm-alloc
#+caption: Schemat kaskadowych alokatorów wykorzystanych w ThesisVM.
#+attr_latex: scale=0.8
[[file:./img/allocator.pdf]]
#+end_center

- Opisać implementację wykorzystanego alokatora.
- Opisać optymalizacje alokatora (wykorzystanie free listy).
- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).
- Opisać krótko alternatywne rozwiązania (mallocator, etc). [[cite:Wilson1995]]

** Kolekcja nieosiągalnych obiektów
- Opisać leniwe zliczanie referencji. [[cite:Boehm2004]]

#+begin_center
#+label: ref:tvm-lazy-refcount-free
#+caption: Schemat działania zwalniania pamięci obiektów.
#+attr_latex: scale=0.8
[[file:./img/lazyrefcountfree.pdf]]
#+end_center

#+begin_center
#+label: ref:tvm-lazy-refcount-alloc
#+caption: Schemat działania alokacji pamięci nowych obiektów.
#+attr_latex: scale=0.8
[[file:./img/lazyrefcountalloc.pdf]]
#+end_center

- Opisać implementację algorytmu leniwego zliczania referencji. [[cite:Bacon2004]]
- Opisać konieczność wykorzystania operacji atomowych i barier pamięci (liczniki referencji).

#+begin_center
#+label: ref:tvm-gc-regs
#+caption: Schemat rejestrów wymaganych przez implementację kolektora obiektów nieosiągalnych.
#+attr_latex: scale=1.5
[[file:./img/GC2.pdf]]
#+end_center

- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).
- Opisać narzut pamięci związany z licznikiem referencji i leniwością algorytmu. cite:Boehm2004,Bacon2004
- Opisać krótko wady, możliwe usprawnienia i alternatywne rozwiązania (zaproponowane przez Joe'go oraz VCGC) [[cite:Armstrong1995,Huelsbergen1998]]

** Kolekcja obiektów cyklicznych
- Opisać, że obiekty cykliczne nie występują.
- Wspomnieć o możliwości zaimplementowania zapasowego stop-the-world GC.
- Wspomnieć o możliwości cyklicznego uruchamiania D'owego GC.

* Model przetwarzania współbieżnego
#+latex: \label{sec:tvm-smp}

- Opisać bardziej szczegółowo Model Aktorowy i asynchroniczne przekazywanie wiadomości. [[cite:Hewitt1973,Clinger1981]]

#+begin_center
#+label: ref:tvm-smp
#+caption: Schemat symetrycznego multiprocesora ThesisVM.
#+attr_latex: scale=1.0
[[file:./img/SMP2.pdf]]
#+end_center

- Opisać bardziej szczegółowo działanie SMP - wiadomości kontrolne oraz RQue.

** Implementacja Modelu Aktorowego
- Opisać powstawanie procesów i prymityw =spawn=.
- Opisać logiczną autonomiczność procesów (brak mutacji = inne procesy nie mogą ingerować).
- Opisać sposób porozumiewania się procesów (kolejki nieblokujące). [[cite:MichaelScott1996,Herlihy2002]]
- Opisać implementację kolejek nieblokujących (+ weryfikacja poprawności). [[cite:MichaelScott1996,Groves2008]]- Opisać wykorzystanie CAS i problem ABA.

#+begin_center
#+label: ref:tvm-actor-regs
#+caption: Schemat rejestrów wymaganych przez implementację Modelu Aktorowego.
#+attr_latex: scale=1.5
[[file:./img/Actor2.pdf]]
#+end_center

- Opisać zmiany wprowadzone w stanie maszyny wirtualnej (dodatkowe rejestry).
- Opisać krótko wady i możliwe usprawnienia zastosowanego rozwiązania (dynamic size, wait-free, optimistic FIFO). [[cite:Herlihy2002,Kogan2011,Ladan-Mozes2004]]
- Opisać krótko alternatywne podejścia (synchroniczne przekazywanie wiadomości - kanały, locki/mutexy/semafory).

** Implementacja przesyłania wiadomości
- Opisać implementację prymitywów =send= oraz =receive=.
- Zwrócić uwagę na konieczność wykorzystania operacji atomowych oraz barier pamięci.
- Snippet kodu przesyłającego wiadomość.

#+begin_center
#+label: ref:tvm-msgs
#+caption: Schemat działania przesyłania wiadomości.
#+attr_latex: scale=1.2
[[file:./img/messagepassing.pdf]]
#+end_center

- Opisać co dzieje się podczas wysyłania wiadomości.
- Opisać sposób pobierania wiadomości z kolejki.
- Zwrócić uwagę na fakt, że problem kopiowania został zniwelowany kosztem lekkich barier pamięci.

** Harmonogramowanie procesów
- Opisać sposób harmonogramowania procesów (brak load-balancingu, losowy spawn).
- Opisać implementację prymitywu =sleep= oraz sleep-table.
- Opisać wiadomości kontrolne.

#+begin_center
#+label: ref:tvm-scheduler-regs
#+caption: Schemat rejestrów wymaganych przez usprawnienia hanmonogramowania SMP.
#+attr_latex: scale=1.5
[[file:./img/Scheduler2.pdf]]
#+end_center

- Opisać możliwe usprawnienia (load-balancing i dzielenie zużycia).

* Podsumowanie
#+latex: \label{sec:conclusion}

- Opisać co udało się zrobić.
- Opisać czego nie udało się zrobić (+ możliwe usprawnienia).

** Leniwe zliczanie referencji
- Przeanalizować szybkość, pauzy, zużycie pamięci.

** Przesyłanie wiadomości
- Przeanalizować szybkość przesyłania wiadomości/konieczność czekania procesów, wielkość kolejek wiadomości.

** Kierunki przyszłego rozwoju
#+latex: \label{sec:future-development}

- Opisać plany na przyszły rozwój projektu (priorytet procesów, load balancing SMP, wsparcie dla =Core Erlang=, bytecode threading, przebiegi optymalizacyjne podczas kompilacji, umożliwienie dystrybucji na wiele maszyn, zapasowy kolektor śmieci cyklicznych, opcja wykorzystania sterty prywatnej i autonomicznego alokatora, natywna kompilacja JIT, wektory, data-level parallelism, optymalizacja wykorzystania stosu, hardłerowa implementacja interpretera kodu bajtowego).

# The bibliography
#+begin_latex
\bibliographystyle{ieeetr}
\bibliography{bibs}
#+end_latex

#+latex: \appendix
* Przykładowe programy
#+latex: \label{sec:tvm-samples}

- Opisać sposób uruchamiania maszyny wirtualnej.
- Hello world.
- Factorial.
- Fibonacci.
- Concurrent Hello world.
- Map-reduce.

* Spisy wbudowanych funkcji i operatorów
#+latex: \label{sec:tvm-primops}

#+begin_latex
{\Large\noindent\textbf{Spis funkcji wbudowanych}}
#+end_latex

- Wylistować funkcje wbudowane.

#+begin_latex
\vspace{2cm}
{\Large\noindent\textbf{Spis operatorów wbudowanych}}
#+end_latex

- Wylistować operacje prymitywne.

* Spisy rysunków, fragmentów kodu i tablic
#+latex: \label{sec:misc}

#+begin_latex
\begingroup
  \renewcommand*{\addvspace}[1]{}
  \listoffigures
  \listofmylisting
  \listoftables
\endgroup
#+end_latex

